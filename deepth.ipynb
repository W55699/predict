{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuhYj6vmQfGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import boston_housing\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import multi_gpu_model\n",
        "from keras import regularizers  # 正则化\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7j-wXYdQfGx",
        "colab_type": "text"
      },
      "source": [
        "## 加载数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0M8hfqEQw8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('precision', 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJt2MGqnRF-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db=pd.read_csv('test.csv',header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaMoqkxfRGaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "2f9500d5-190b-4785-c549-70bee57440ba"
      },
      "source": [
        "db=db.dropna(axis='columns')\n",
        "db"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>output</td>\n",
              "      <td>deepth</td>\n",
              "      <td>one step</td>\n",
              "      <td>two step</td>\n",
              "      <td>three step</td>\n",
              "      <td>four step</td>\n",
              "      <td>five step</td>\n",
              "      <td>six step</td>\n",
              "      <td>seven step</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>400</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>400</td>\n",
              "      <td>60</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>400</td>\n",
              "      <td>90</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.46E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>400</td>\n",
              "      <td>120</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>400</td>\n",
              "      <td>150</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.46E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>925</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>925</td>\n",
              "      <td>60</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>925</td>\n",
              "      <td>90</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.46E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>925</td>\n",
              "      <td>120</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.46E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>925</td>\n",
              "      <td>150</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.25E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.40E-05</td>\n",
              "      <td>8.46E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>995</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>995</td>\n",
              "      <td>60</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>995</td>\n",
              "      <td>90</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>995</td>\n",
              "      <td>120</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>995</td>\n",
              "      <td>150</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1200</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.40E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1200</td>\n",
              "      <td>60</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1200</td>\n",
              "      <td>90</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1200</td>\n",
              "      <td>120</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1200</td>\n",
              "      <td>150</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.31E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>500</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>500</td>\n",
              "      <td>60</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>500</td>\n",
              "      <td>90</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>500</td>\n",
              "      <td>120</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>500</td>\n",
              "      <td>150</td>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1         2  ...          6         7           8\n",
              "0   output  deepth  one step  ...  five step  six step  seven step\n",
              "1      400      30  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "2      400      60  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "3      400      90  1.00E-05  ...   8.39E-05  8.46E-05    2.81E-04\n",
              "4      400     120  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "5      400     150  1.00E-05  ...   8.39E-05  8.46E-05    2.81E-05\n",
              "6      925      30  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "7      925      60  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "8      925      90  1.00E-05  ...   8.39E-05  8.46E-05    2.81E-04\n",
              "9      925     120  1.00E-05  ...   8.39E-05  8.46E-05    2.81E-04\n",
              "10     925     150  1.00E-05  ...   8.40E-05  8.46E-05    2.81E-04\n",
              "11     995      30  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "12     995      60  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "13     995      90  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "14     995     120  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "15     995     150  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-05\n",
              "16    1200      30  1.00E-05  ...   8.40E-05  8.47E-05    2.81E-04\n",
              "17    1200      60  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-05\n",
              "18    1200      90  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "19    1200     120  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "20    1200     150  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-05\n",
              "21     500      30  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "22     500      60  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-05\n",
              "23     500      90  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "24     500     120  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-05\n",
              "25     500     150  1.00E-05  ...   8.39E-05  8.47E-05    2.81E-04\n",
              "\n",
              "[26 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEy-v24fQfGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "352bed12-e0dc-458a-b4b2-d7e53b446b0a"
      },
      "source": [
        "db=pd.DataFrame(db) # 加载数据\n",
        "\n",
        "y_train=db.loc[1:20,0]\n",
        "y_test=db.iloc[21:26,0]\n",
        "\n",
        "x_train=db.loc[1:20,2:9]\n",
        "x_test=db.iloc[21:26,2:9]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 转成DataFrame格式方便数据处理\n",
        "x_train_pd = pd.DataFrame(x_train)\n",
        "y_train_pd = pd.DataFrame(y_train)\n",
        "x_valid_pd = pd.DataFrame(x_test)\n",
        "y_valid_pd = pd.DataFrame(y_test)\n",
        "print(x_train_pd.head(5))\n",
        "print('-------------------')\n",
        "print(y_train_pd.head(5))\n",
        "print(x_test)\n",
        "print(y_test)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          2         3         4         5         6         7         8\n",
            "1  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "2  1.00E-05  8.19E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "3  1.00E-05  8.20E-05  8.25E-05  8.31E-05  8.39E-05  8.46E-05  2.81E-04\n",
            "4  1.00E-05  8.19E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "5  1.00E-05  8.19E-05  8.25E-05  8.32E-05  8.39E-05  8.46E-05  2.81E-05\n",
            "-------------------\n",
            "     0\n",
            "1  400\n",
            "2  400\n",
            "3  400\n",
            "4  400\n",
            "5  400\n",
            "           2         3         4         5         6         7         8\n",
            "21  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "22  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-05\n",
            "23  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "24  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-05\n",
            "25  1.00E-05  8.19E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
            "21    500\n",
            "22    500\n",
            "23    500\n",
            "24    500\n",
            "25    500\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0vfNMGgb5oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "91543305-124b-4487-e203-b4a1d4d6be55"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.20E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1.00E-05</td>\n",
              "      <td>8.19E-05</td>\n",
              "      <td>8.26E-05</td>\n",
              "      <td>8.32E-05</td>\n",
              "      <td>8.39E-05</td>\n",
              "      <td>8.47E-05</td>\n",
              "      <td>2.81E-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           2         3         4         5         6         7         8\n",
              "21  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
              "22  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-05\n",
              "23  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04\n",
              "24  1.00E-05  8.20E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-05\n",
              "25  1.00E-05  8.19E-05  8.26E-05  8.32E-05  8.39E-05  8.47E-05  2.81E-04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5KMnFWxcQZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "bdd23fea-2aa0-4096-9353-acae6d7e8305"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21    500\n",
              "22    500\n",
              "23    500\n",
              "24    500\n",
              "25    500\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaH9wp_nQfG9",
        "colab_type": "text"
      },
      "source": [
        "## 数据归一化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8oE1DxNQfG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练集归一化\n",
        "min_max_scaler = MinMaxScaler()\n",
        "min_max_scaler.fit(x_train_pd)\n",
        "x_train = min_max_scaler.transform(x_train_pd)\n",
        "\n",
        "min_max_scaler.fit(y_train_pd)\n",
        "y_train = min_max_scaler.transform(y_train_pd)\n",
        "\n",
        "# 验证集归一化\n",
        "min_max_scaler.fit(x_valid_pd)\n",
        "x_valid = min_max_scaler.transform(x_valid_pd)\n",
        "\n",
        "min_max_scaler.fit(y_valid_pd)\n",
        "y_valid = min_max_scaler.transform(y_valid_pd)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTVJ6YfNc1uR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "462da2ab-a1b9-451e-9b70-67155a2739e7"
      },
      "source": [
        "x_valid.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMefa3v9c7NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "4cdfa92d-bffc-4834-ad3d-e40f90c6bd6e"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.     ],\n",
              "       [0.     ],\n",
              "       [0.     ],\n",
              "       [0.     ],\n",
              "       [0.     ],\n",
              "       [0.65625],\n",
              "       [0.65625],\n",
              "       [0.65625],\n",
              "       [0.65625],\n",
              "       [0.65625],\n",
              "       [0.74375],\n",
              "       [0.74375],\n",
              "       [0.74375],\n",
              "       [0.74375],\n",
              "       [0.74375],\n",
              "       [1.     ],\n",
              "       [1.     ],\n",
              "       [1.     ],\n",
              "       [1.     ],\n",
              "       [1.     ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoZza3kzea4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "de4fab5c-5465-4642-a413-9d326e92115e"
      },
      "source": [
        "x_train"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., 1., 0., 1., 1.],\n",
              "       [0., 0., 1., 1., 0., 1., 1.],\n",
              "       [0., 1., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 1., 0., 1., 1.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 1., 1.],\n",
              "       [0., 1., 0., 1., 0., 1., 1.],\n",
              "       [0., 0., 0., 1., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 1., 0., 1.],\n",
              "       [0., 1., 1., 0., 0., 1., 1.],\n",
              "       [0., 1., 1., 0., 0., 1., 1.],\n",
              "       [0., 0., 1., 1., 0., 1., 1.],\n",
              "       [0., 0., 1., 0., 0., 1., 1.],\n",
              "       [0., 0., 1., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 1., 1., 1., 1.],\n",
              "       [0., 0., 1., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0., 1., 1.],\n",
              "       [0., 0., 1., 0., 0., 1., 1.],\n",
              "       [0., 0., 1., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkf98CJiQfHH",
        "colab_type": "text"
      },
      "source": [
        "## 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYIMkmzQfHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5de51d22-8a28-4853-822a-6ebf88e468f8"
      },
      "source": [
        "\n",
        "# 单CPU or GPU版本，若有GPU则自动切换\n",
        "model = Sequential()  # 初始化，很重要！\n",
        "model.add(Dense(units = 10,   # 输出大小\n",
        "                activation='relu',  # 激励函数\n",
        "                input_shape=(x_train_pd.shape[1],)  # 输入大小, 也就是列的大小\n",
        "               )\n",
        "         )\n",
        "\n",
        "model.add(Dropout(0.2))  # 丢弃神经元链接概率\n",
        "\n",
        "model.add(Dense(units = 15,\n",
        "#                 kernel_regularizer=regularizers.l2(0.01),  # 施加在权重上的正则项\n",
        "#                 activity_regularizer=regularizers.l1(0.01),  # 施加在输出上的正则项\n",
        "                activation='relu' # 激励函数\n",
        "                # bias_regularizer=keras.regularizers.l1_l2(0.01)  # 施加在偏置向量上的正则项\n",
        "               )\n",
        "         )\n",
        "\n",
        "model.add(Dense(units = 1,   \n",
        "                activation='linear'  # 线性激励函数 回归一般在输出层用这个激励函数  \n",
        "               )\n",
        "         )\n",
        "\n",
        "print(model.summary())  # 打印网络层次结构\n",
        "\n",
        "model.compile(loss='mse',  # 损失均方误差\n",
        "              optimizer='adam',  # 优化器\n",
        "             )\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          epochs=1000,  # 迭代次数\n",
        "          batch_size=200,  # 每次用来梯度下降的批处理数据大小\n",
        "          verbose=2,  # verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：输出训练进度，2：输出每一个epoch\n",
        "          validation_data = (x_valid, y_valid)  # 验证集\n",
        "        )\n",
        "\n",
        "# 多GPU版本\n",
        "# parallel_model = multi_gpu_model(model, gpus=4)\n",
        "# parallel_model.compile(loss='mse',  # 多分类     \n",
        "#                        optimizer='adam',\n",
        "#                       )\n",
        "\n",
        "# This `fit` call will be distributed on 4 GPUs.\n",
        "# Since the batch size is 50, each GPU will process 32 samples.\n",
        "# batch_size = 512\n",
        "# epochs = 2\n",
        "# history = parallel_model.fit(\n",
        "#           x_train, \n",
        "#           y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           validation_split = 0.2  # 从训练集分割出20%的数据作为验证集\n",
        "#         )"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 10)                80        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 15)                165       \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 261\n",
            "Trainable params: 261\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 20 samples, validate on 5 samples\n",
            "Epoch 1/1000\n",
            " - 1s - loss: 0.5633 - val_loss: 0.0473\n",
            "Epoch 2/1000\n",
            " - 0s - loss: 0.5505 - val_loss: 0.0437\n",
            "Epoch 3/1000\n",
            " - 0s - loss: 0.5493 - val_loss: 0.0403\n",
            "Epoch 4/1000\n",
            " - 0s - loss: 0.5837 - val_loss: 0.0371\n",
            "Epoch 5/1000\n",
            " - 0s - loss: 0.4982 - val_loss: 0.0340\n",
            "Epoch 6/1000\n",
            " - 0s - loss: 0.4922 - val_loss: 0.0311\n",
            "Epoch 7/1000\n",
            " - 0s - loss: 0.4513 - val_loss: 0.0284\n",
            "Epoch 8/1000\n",
            " - 0s - loss: 0.4716 - val_loss: 0.0258\n",
            "Epoch 9/1000\n",
            " - 0s - loss: 0.4462 - val_loss: 0.0234\n",
            "Epoch 10/1000\n",
            " - 0s - loss: 0.4844 - val_loss: 0.0211\n",
            "Epoch 11/1000\n",
            " - 0s - loss: 0.4436 - val_loss: 0.0189\n",
            "Epoch 12/1000\n",
            " - 0s - loss: 0.4405 - val_loss: 0.0168\n",
            "Epoch 13/1000\n",
            " - 0s - loss: 0.4022 - val_loss: 0.0150\n",
            "Epoch 14/1000\n",
            " - 0s - loss: 0.3836 - val_loss: 0.0133\n",
            "Epoch 15/1000\n",
            " - 0s - loss: 0.3510 - val_loss: 0.0118\n",
            "Epoch 16/1000\n",
            " - 0s - loss: 0.3496 - val_loss: 0.0105\n",
            "Epoch 17/1000\n",
            " - 0s - loss: 0.3469 - val_loss: 0.0093\n",
            "Epoch 18/1000\n",
            " - 0s - loss: 0.3063 - val_loss: 0.0083\n",
            "Epoch 19/1000\n",
            " - 0s - loss: 0.2641 - val_loss: 0.0074\n",
            "Epoch 20/1000\n",
            " - 0s - loss: 0.2972 - val_loss: 0.0068\n",
            "Epoch 21/1000\n",
            " - 0s - loss: 0.2647 - val_loss: 0.0062\n",
            "Epoch 22/1000\n",
            " - 0s - loss: 0.2757 - val_loss: 0.0058\n",
            "Epoch 23/1000\n",
            " - 0s - loss: 0.2688 - val_loss: 0.0055\n",
            "Epoch 24/1000\n",
            " - 0s - loss: 0.2847 - val_loss: 0.0053\n",
            "Epoch 25/1000\n",
            " - 0s - loss: 0.2699 - val_loss: 0.0052\n",
            "Epoch 26/1000\n",
            " - 0s - loss: 0.2039 - val_loss: 0.0053\n",
            "Epoch 27/1000\n",
            " - 0s - loss: 0.1948 - val_loss: 0.0055\n",
            "Epoch 28/1000\n",
            " - 0s - loss: 0.2653 - val_loss: 0.0058\n",
            "Epoch 29/1000\n",
            " - 0s - loss: 0.2129 - val_loss: 0.0061\n",
            "Epoch 30/1000\n",
            " - 0s - loss: 0.1975 - val_loss: 0.0066\n",
            "Epoch 31/1000\n",
            " - 0s - loss: 0.2202 - val_loss: 0.0071\n",
            "Epoch 32/1000\n",
            " - 0s - loss: 0.2030 - val_loss: 0.0078\n",
            "Epoch 33/1000\n",
            " - 0s - loss: 0.1962 - val_loss: 0.0085\n",
            "Epoch 34/1000\n",
            " - 0s - loss: 0.2452 - val_loss: 0.0092\n",
            "Epoch 35/1000\n",
            " - 0s - loss: 0.1684 - val_loss: 0.0100\n",
            "Epoch 36/1000\n",
            " - 0s - loss: 0.2199 - val_loss: 0.0109\n",
            "Epoch 37/1000\n",
            " - 0s - loss: 0.2058 - val_loss: 0.0118\n",
            "Epoch 38/1000\n",
            " - 0s - loss: 0.1703 - val_loss: 0.0128\n",
            "Epoch 39/1000\n",
            " - 0s - loss: 0.1772 - val_loss: 0.0137\n",
            "Epoch 40/1000\n",
            " - 0s - loss: 0.1750 - val_loss: 0.0147\n",
            "Epoch 41/1000\n",
            " - 0s - loss: 0.2033 - val_loss: 0.0157\n",
            "Epoch 42/1000\n",
            " - 0s - loss: 0.1902 - val_loss: 0.0167\n",
            "Epoch 43/1000\n",
            " - 0s - loss: 0.1451 - val_loss: 0.0177\n",
            "Epoch 44/1000\n",
            " - 0s - loss: 0.1773 - val_loss: 0.0188\n",
            "Epoch 45/1000\n",
            " - 0s - loss: 0.1364 - val_loss: 0.0198\n",
            "Epoch 46/1000\n",
            " - 0s - loss: 0.1347 - val_loss: 0.0208\n",
            "Epoch 47/1000\n",
            " - 0s - loss: 0.1225 - val_loss: 0.0218\n",
            "Epoch 48/1000\n",
            " - 0s - loss: 0.1479 - val_loss: 0.0228\n",
            "Epoch 49/1000\n",
            " - 0s - loss: 0.1537 - val_loss: 0.0237\n",
            "Epoch 50/1000\n",
            " - 0s - loss: 0.1845 - val_loss: 0.0245\n",
            "Epoch 51/1000\n",
            " - 0s - loss: 0.1116 - val_loss: 0.0254\n",
            "Epoch 52/1000\n",
            " - 0s - loss: 0.1352 - val_loss: 0.0263\n",
            "Epoch 53/1000\n",
            " - 0s - loss: 0.1617 - val_loss: 0.0272\n",
            "Epoch 54/1000\n",
            " - 0s - loss: 0.1498 - val_loss: 0.0281\n",
            "Epoch 55/1000\n",
            " - 0s - loss: 0.0957 - val_loss: 0.0289\n",
            "Epoch 56/1000\n",
            " - 0s - loss: 0.1431 - val_loss: 0.0297\n",
            "Epoch 57/1000\n",
            " - 0s - loss: 0.1553 - val_loss: 0.0304\n",
            "Epoch 58/1000\n",
            " - 0s - loss: 0.1944 - val_loss: 0.0311\n",
            "Epoch 59/1000\n",
            " - 0s - loss: 0.1245 - val_loss: 0.0317\n",
            "Epoch 60/1000\n",
            " - 0s - loss: 0.1401 - val_loss: 0.0323\n",
            "Epoch 61/1000\n",
            " - 0s - loss: 0.1457 - val_loss: 0.0328\n",
            "Epoch 62/1000\n",
            " - 0s - loss: 0.1645 - val_loss: 0.0334\n",
            "Epoch 63/1000\n",
            " - 0s - loss: 0.1236 - val_loss: 0.0339\n",
            "Epoch 64/1000\n",
            " - 0s - loss: 0.1351 - val_loss: 0.0344\n",
            "Epoch 65/1000\n",
            " - 0s - loss: 0.1408 - val_loss: 0.0349\n",
            "Epoch 66/1000\n",
            " - 0s - loss: 0.1216 - val_loss: 0.0353\n",
            "Epoch 67/1000\n",
            " - 0s - loss: 0.1685 - val_loss: 0.0355\n",
            "Epoch 68/1000\n",
            " - 0s - loss: 0.1073 - val_loss: 0.0358\n",
            "Epoch 69/1000\n",
            " - 0s - loss: 0.1394 - val_loss: 0.0360\n",
            "Epoch 70/1000\n",
            " - 0s - loss: 0.1903 - val_loss: 0.0362\n",
            "Epoch 71/1000\n",
            " - 0s - loss: 0.1491 - val_loss: 0.0365\n",
            "Epoch 72/1000\n",
            " - 0s - loss: 0.1001 - val_loss: 0.0368\n",
            "Epoch 73/1000\n",
            " - 0s - loss: 0.1199 - val_loss: 0.0370\n",
            "Epoch 74/1000\n",
            " - 0s - loss: 0.1161 - val_loss: 0.0373\n",
            "Epoch 75/1000\n",
            " - 0s - loss: 0.1134 - val_loss: 0.0375\n",
            "Epoch 76/1000\n",
            " - 0s - loss: 0.1040 - val_loss: 0.0376\n",
            "Epoch 77/1000\n",
            " - 0s - loss: 0.1031 - val_loss: 0.0378\n",
            "Epoch 78/1000\n",
            " - 0s - loss: 0.0998 - val_loss: 0.0379\n",
            "Epoch 79/1000\n",
            " - 0s - loss: 0.1304 - val_loss: 0.0381\n",
            "Epoch 80/1000\n",
            " - 0s - loss: 0.0904 - val_loss: 0.0383\n",
            "Epoch 81/1000\n",
            " - 0s - loss: 0.0894 - val_loss: 0.0385\n",
            "Epoch 82/1000\n",
            " - 0s - loss: 0.1153 - val_loss: 0.0386\n",
            "Epoch 83/1000\n",
            " - 0s - loss: 0.1113 - val_loss: 0.0388\n",
            "Epoch 84/1000\n",
            " - 0s - loss: 0.1246 - val_loss: 0.0389\n",
            "Epoch 85/1000\n",
            " - 0s - loss: 0.0932 - val_loss: 0.0390\n",
            "Epoch 86/1000\n",
            " - 0s - loss: 0.1370 - val_loss: 0.0392\n",
            "Epoch 87/1000\n",
            " - 0s - loss: 0.1396 - val_loss: 0.0393\n",
            "Epoch 88/1000\n",
            " - 0s - loss: 0.1238 - val_loss: 0.0396\n",
            "Epoch 89/1000\n",
            " - 0s - loss: 0.1377 - val_loss: 0.0400\n",
            "Epoch 90/1000\n",
            " - 0s - loss: 0.0953 - val_loss: 0.0403\n",
            "Epoch 91/1000\n",
            " - 0s - loss: 0.0902 - val_loss: 0.0407\n",
            "Epoch 92/1000\n",
            " - 0s - loss: 0.1211 - val_loss: 0.0409\n",
            "Epoch 93/1000\n",
            " - 0s - loss: 0.1309 - val_loss: 0.0412\n",
            "Epoch 94/1000\n",
            " - 0s - loss: 0.1135 - val_loss: 0.0414\n",
            "Epoch 95/1000\n",
            " - 0s - loss: 0.0995 - val_loss: 0.0416\n",
            "Epoch 96/1000\n",
            " - 0s - loss: 0.0922 - val_loss: 0.0419\n",
            "Epoch 97/1000\n",
            " - 0s - loss: 0.1249 - val_loss: 0.0422\n",
            "Epoch 98/1000\n",
            " - 0s - loss: 0.0835 - val_loss: 0.0424\n",
            "Epoch 99/1000\n",
            " - 0s - loss: 0.1625 - val_loss: 0.0426\n",
            "Epoch 100/1000\n",
            " - 0s - loss: 0.1181 - val_loss: 0.0429\n",
            "Epoch 101/1000\n",
            " - 0s - loss: 0.1497 - val_loss: 0.0431\n",
            "Epoch 102/1000\n",
            " - 0s - loss: 0.1290 - val_loss: 0.0434\n",
            "Epoch 103/1000\n",
            " - 0s - loss: 0.0903 - val_loss: 0.0436\n",
            "Epoch 104/1000\n",
            " - 0s - loss: 0.1635 - val_loss: 0.0439\n",
            "Epoch 105/1000\n",
            " - 0s - loss: 0.1364 - val_loss: 0.0442\n",
            "Epoch 106/1000\n",
            " - 0s - loss: 0.1328 - val_loss: 0.0445\n",
            "Epoch 107/1000\n",
            " - 0s - loss: 0.1238 - val_loss: 0.0448\n",
            "Epoch 108/1000\n",
            " - 0s - loss: 0.1302 - val_loss: 0.0452\n",
            "Epoch 109/1000\n",
            " - 0s - loss: 0.1327 - val_loss: 0.0457\n",
            "Epoch 110/1000\n",
            " - 0s - loss: 0.0877 - val_loss: 0.0461\n",
            "Epoch 111/1000\n",
            " - 0s - loss: 0.0871 - val_loss: 0.0465\n",
            "Epoch 112/1000\n",
            " - 0s - loss: 0.0759 - val_loss: 0.0469\n",
            "Epoch 113/1000\n",
            " - 0s - loss: 0.0871 - val_loss: 0.0473\n",
            "Epoch 114/1000\n",
            " - 0s - loss: 0.0889 - val_loss: 0.0477\n",
            "Epoch 115/1000\n",
            " - 0s - loss: 0.1035 - val_loss: 0.0480\n",
            "Epoch 116/1000\n",
            " - 0s - loss: 0.1109 - val_loss: 0.0482\n",
            "Epoch 117/1000\n",
            " - 0s - loss: 0.0881 - val_loss: 0.0484\n",
            "Epoch 118/1000\n",
            " - 0s - loss: 0.0969 - val_loss: 0.0486\n",
            "Epoch 119/1000\n",
            " - 0s - loss: 0.1123 - val_loss: 0.0489\n",
            "Epoch 120/1000\n",
            " - 0s - loss: 0.0911 - val_loss: 0.0492\n",
            "Epoch 121/1000\n",
            " - 0s - loss: 0.0788 - val_loss: 0.0496\n",
            "Epoch 122/1000\n",
            " - 0s - loss: 0.0969 - val_loss: 0.0499\n",
            "Epoch 123/1000\n",
            " - 0s - loss: 0.0965 - val_loss: 0.0501\n",
            "Epoch 124/1000\n",
            " - 0s - loss: 0.1268 - val_loss: 0.0504\n",
            "Epoch 125/1000\n",
            " - 0s - loss: 0.0819 - val_loss: 0.0507\n",
            "Epoch 126/1000\n",
            " - 0s - loss: 0.1220 - val_loss: 0.0509\n",
            "Epoch 127/1000\n",
            " - 0s - loss: 0.0895 - val_loss: 0.0511\n",
            "Epoch 128/1000\n",
            " - 0s - loss: 0.1001 - val_loss: 0.0513\n",
            "Epoch 129/1000\n",
            " - 0s - loss: 0.1089 - val_loss: 0.0516\n",
            "Epoch 130/1000\n",
            " - 0s - loss: 0.1007 - val_loss: 0.0519\n",
            "Epoch 131/1000\n",
            " - 0s - loss: 0.1054 - val_loss: 0.0522\n",
            "Epoch 132/1000\n",
            " - 0s - loss: 0.0774 - val_loss: 0.0524\n",
            "Epoch 133/1000\n",
            " - 0s - loss: 0.1024 - val_loss: 0.0526\n",
            "Epoch 134/1000\n",
            " - 0s - loss: 0.0746 - val_loss: 0.0528\n",
            "Epoch 135/1000\n",
            " - 0s - loss: 0.1077 - val_loss: 0.0531\n",
            "Epoch 136/1000\n",
            " - 0s - loss: 0.1666 - val_loss: 0.0534\n",
            "Epoch 137/1000\n",
            " - 0s - loss: 0.0772 - val_loss: 0.0538\n",
            "Epoch 138/1000\n",
            " - 0s - loss: 0.0850 - val_loss: 0.0543\n",
            "Epoch 139/1000\n",
            " - 0s - loss: 0.0981 - val_loss: 0.0548\n",
            "Epoch 140/1000\n",
            " - 0s - loss: 0.1365 - val_loss: 0.0552\n",
            "Epoch 141/1000\n",
            " - 0s - loss: 0.0553 - val_loss: 0.0556\n",
            "Epoch 142/1000\n",
            " - 0s - loss: 0.0811 - val_loss: 0.0560\n",
            "Epoch 143/1000\n",
            " - 0s - loss: 0.0969 - val_loss: 0.0563\n",
            "Epoch 144/1000\n",
            " - 0s - loss: 0.0755 - val_loss: 0.0566\n",
            "Epoch 145/1000\n",
            " - 0s - loss: 0.1600 - val_loss: 0.0569\n",
            "Epoch 146/1000\n",
            " - 0s - loss: 0.0840 - val_loss: 0.0572\n",
            "Epoch 147/1000\n",
            " - 0s - loss: 0.0864 - val_loss: 0.0574\n",
            "Epoch 148/1000\n",
            " - 0s - loss: 0.0869 - val_loss: 0.0574\n",
            "Epoch 149/1000\n",
            " - 0s - loss: 0.0995 - val_loss: 0.0575\n",
            "Epoch 150/1000\n",
            " - 0s - loss: 0.1037 - val_loss: 0.0575\n",
            "Epoch 151/1000\n",
            " - 0s - loss: 0.0938 - val_loss: 0.0576\n",
            "Epoch 152/1000\n",
            " - 0s - loss: 0.0961 - val_loss: 0.0576\n",
            "Epoch 153/1000\n",
            " - 0s - loss: 0.0856 - val_loss: 0.0575\n",
            "Epoch 154/1000\n",
            " - 0s - loss: 0.0865 - val_loss: 0.0575\n",
            "Epoch 155/1000\n",
            " - 0s - loss: 0.1152 - val_loss: 0.0575\n",
            "Epoch 156/1000\n",
            " - 0s - loss: 0.1013 - val_loss: 0.0575\n",
            "Epoch 157/1000\n",
            " - 0s - loss: 0.1148 - val_loss: 0.0576\n",
            "Epoch 158/1000\n",
            " - 0s - loss: 0.0993 - val_loss: 0.0575\n",
            "Epoch 159/1000\n",
            " - 0s - loss: 0.0564 - val_loss: 0.0573\n",
            "Epoch 160/1000\n",
            " - 0s - loss: 0.0821 - val_loss: 0.0571\n",
            "Epoch 161/1000\n",
            " - 0s - loss: 0.1059 - val_loss: 0.0570\n",
            "Epoch 162/1000\n",
            " - 0s - loss: 0.0573 - val_loss: 0.0569\n",
            "Epoch 163/1000\n",
            " - 0s - loss: 0.0732 - val_loss: 0.0569\n",
            "Epoch 164/1000\n",
            " - 0s - loss: 0.0740 - val_loss: 0.0569\n",
            "Epoch 165/1000\n",
            " - 0s - loss: 0.0911 - val_loss: 0.0569\n",
            "Epoch 166/1000\n",
            " - 0s - loss: 0.0849 - val_loss: 0.0570\n",
            "Epoch 167/1000\n",
            " - 0s - loss: 0.0877 - val_loss: 0.0571\n",
            "Epoch 168/1000\n",
            " - 0s - loss: 0.0736 - val_loss: 0.0572\n",
            "Epoch 169/1000\n",
            " - 0s - loss: 0.0799 - val_loss: 0.0573\n",
            "Epoch 170/1000\n",
            " - 0s - loss: 0.1125 - val_loss: 0.0572\n",
            "Epoch 171/1000\n",
            " - 0s - loss: 0.0800 - val_loss: 0.0572\n",
            "Epoch 172/1000\n",
            " - 0s - loss: 0.0605 - val_loss: 0.0572\n",
            "Epoch 173/1000\n",
            " - 0s - loss: 0.0927 - val_loss: 0.0572\n",
            "Epoch 174/1000\n",
            " - 0s - loss: 0.0725 - val_loss: 0.0572\n",
            "Epoch 175/1000\n",
            " - 0s - loss: 0.0829 - val_loss: 0.0571\n",
            "Epoch 176/1000\n",
            " - 0s - loss: 0.0818 - val_loss: 0.0570\n",
            "Epoch 177/1000\n",
            " - 0s - loss: 0.0953 - val_loss: 0.0570\n",
            "Epoch 178/1000\n",
            " - 0s - loss: 0.0780 - val_loss: 0.0570\n",
            "Epoch 179/1000\n",
            " - 0s - loss: 0.0969 - val_loss: 0.0571\n",
            "Epoch 180/1000\n",
            " - 0s - loss: 0.0877 - val_loss: 0.0572\n",
            "Epoch 181/1000\n",
            " - 0s - loss: 0.0654 - val_loss: 0.0575\n",
            "Epoch 182/1000\n",
            " - 0s - loss: 0.0872 - val_loss: 0.0576\n",
            "Epoch 183/1000\n",
            " - 0s - loss: 0.0998 - val_loss: 0.0578\n",
            "Epoch 184/1000\n",
            " - 0s - loss: 0.0921 - val_loss: 0.0581\n",
            "Epoch 185/1000\n",
            " - 0s - loss: 0.0710 - val_loss: 0.0583\n",
            "Epoch 186/1000\n",
            " - 0s - loss: 0.0810 - val_loss: 0.0587\n",
            "Epoch 187/1000\n",
            " - 0s - loss: 0.0826 - val_loss: 0.0592\n",
            "Epoch 188/1000\n",
            " - 0s - loss: 0.0832 - val_loss: 0.0596\n",
            "Epoch 189/1000\n",
            " - 0s - loss: 0.1252 - val_loss: 0.0600\n",
            "Epoch 190/1000\n",
            " - 0s - loss: 0.0960 - val_loss: 0.0604\n",
            "Epoch 191/1000\n",
            " - 0s - loss: 0.0673 - val_loss: 0.0607\n",
            "Epoch 192/1000\n",
            " - 0s - loss: 0.0958 - val_loss: 0.0610\n",
            "Epoch 193/1000\n",
            " - 0s - loss: 0.1025 - val_loss: 0.0614\n",
            "Epoch 194/1000\n",
            " - 0s - loss: 0.0798 - val_loss: 0.0619\n",
            "Epoch 195/1000\n",
            " - 0s - loss: 0.0514 - val_loss: 0.0622\n",
            "Epoch 196/1000\n",
            " - 0s - loss: 0.0978 - val_loss: 0.0625\n",
            "Epoch 197/1000\n",
            " - 0s - loss: 0.0669 - val_loss: 0.0628\n",
            "Epoch 198/1000\n",
            " - 0s - loss: 0.0714 - val_loss: 0.0630\n",
            "Epoch 199/1000\n",
            " - 0s - loss: 0.1010 - val_loss: 0.0633\n",
            "Epoch 200/1000\n",
            " - 0s - loss: 0.0873 - val_loss: 0.0635\n",
            "Epoch 201/1000\n",
            " - 0s - loss: 0.0789 - val_loss: 0.0637\n",
            "Epoch 202/1000\n",
            " - 0s - loss: 0.0650 - val_loss: 0.0638\n",
            "Epoch 203/1000\n",
            " - 0s - loss: 0.0816 - val_loss: 0.0640\n",
            "Epoch 204/1000\n",
            " - 0s - loss: 0.0811 - val_loss: 0.0640\n",
            "Epoch 205/1000\n",
            " - 0s - loss: 0.0829 - val_loss: 0.0639\n",
            "Epoch 206/1000\n",
            " - 0s - loss: 0.0989 - val_loss: 0.0636\n",
            "Epoch 207/1000\n",
            " - 0s - loss: 0.0535 - val_loss: 0.0634\n",
            "Epoch 208/1000\n",
            " - 0s - loss: 0.0609 - val_loss: 0.0631\n",
            "Epoch 209/1000\n",
            " - 0s - loss: 0.0920 - val_loss: 0.0628\n",
            "Epoch 210/1000\n",
            " - 0s - loss: 0.0760 - val_loss: 0.0624\n",
            "Epoch 211/1000\n",
            " - 0s - loss: 0.0646 - val_loss: 0.0621\n",
            "Epoch 212/1000\n",
            " - 0s - loss: 0.0581 - val_loss: 0.0618\n",
            "Epoch 213/1000\n",
            " - 0s - loss: 0.0639 - val_loss: 0.0616\n",
            "Epoch 214/1000\n",
            " - 0s - loss: 0.1264 - val_loss: 0.0614\n",
            "Epoch 215/1000\n",
            " - 0s - loss: 0.0910 - val_loss: 0.0613\n",
            "Epoch 216/1000\n",
            " - 0s - loss: 0.0622 - val_loss: 0.0612\n",
            "Epoch 217/1000\n",
            " - 0s - loss: 0.0577 - val_loss: 0.0611\n",
            "Epoch 218/1000\n",
            " - 0s - loss: 0.0828 - val_loss: 0.0610\n",
            "Epoch 219/1000\n",
            " - 0s - loss: 0.0889 - val_loss: 0.0610\n",
            "Epoch 220/1000\n",
            " - 0s - loss: 0.0798 - val_loss: 0.0609\n",
            "Epoch 221/1000\n",
            " - 0s - loss: 0.0865 - val_loss: 0.0607\n",
            "Epoch 222/1000\n",
            " - 0s - loss: 0.0727 - val_loss: 0.0606\n",
            "Epoch 223/1000\n",
            " - 0s - loss: 0.0660 - val_loss: 0.0605\n",
            "Epoch 224/1000\n",
            " - 0s - loss: 0.0722 - val_loss: 0.0604\n",
            "Epoch 225/1000\n",
            " - 0s - loss: 0.0674 - val_loss: 0.0603\n",
            "Epoch 226/1000\n",
            " - 0s - loss: 0.0812 - val_loss: 0.0601\n",
            "Epoch 227/1000\n",
            " - 0s - loss: 0.1031 - val_loss: 0.0599\n",
            "Epoch 228/1000\n",
            " - 0s - loss: 0.0604 - val_loss: 0.0598\n",
            "Epoch 229/1000\n",
            " - 0s - loss: 0.0665 - val_loss: 0.0598\n",
            "Epoch 230/1000\n",
            " - 0s - loss: 0.0682 - val_loss: 0.0598\n",
            "Epoch 231/1000\n",
            " - 0s - loss: 0.0634 - val_loss: 0.0598\n",
            "Epoch 232/1000\n",
            " - 0s - loss: 0.0749 - val_loss: 0.0599\n",
            "Epoch 233/1000\n",
            " - 0s - loss: 0.0812 - val_loss: 0.0598\n",
            "Epoch 234/1000\n",
            " - 0s - loss: 0.0561 - val_loss: 0.0598\n",
            "Epoch 235/1000\n",
            " - 0s - loss: 0.0877 - val_loss: 0.0598\n",
            "Epoch 236/1000\n",
            " - 0s - loss: 0.0451 - val_loss: 0.0598\n",
            "Epoch 237/1000\n",
            " - 0s - loss: 0.0830 - val_loss: 0.0597\n",
            "Epoch 238/1000\n",
            " - 0s - loss: 0.0711 - val_loss: 0.0596\n",
            "Epoch 239/1000\n",
            " - 0s - loss: 0.0502 - val_loss: 0.0595\n",
            "Epoch 240/1000\n",
            " - 0s - loss: 0.0641 - val_loss: 0.0594\n",
            "Epoch 241/1000\n",
            " - 0s - loss: 0.0774 - val_loss: 0.0592\n",
            "Epoch 242/1000\n",
            " - 0s - loss: 0.0629 - val_loss: 0.0591\n",
            "Epoch 243/1000\n",
            " - 0s - loss: 0.0646 - val_loss: 0.0589\n",
            "Epoch 244/1000\n",
            " - 0s - loss: 0.0862 - val_loss: 0.0589\n",
            "Epoch 245/1000\n",
            " - 0s - loss: 0.0467 - val_loss: 0.0588\n",
            "Epoch 246/1000\n",
            " - 0s - loss: 0.1063 - val_loss: 0.0588\n",
            "Epoch 247/1000\n",
            " - 0s - loss: 0.0759 - val_loss: 0.0589\n",
            "Epoch 248/1000\n",
            " - 0s - loss: 0.0575 - val_loss: 0.0589\n",
            "Epoch 249/1000\n",
            " - 0s - loss: 0.0554 - val_loss: 0.0590\n",
            "Epoch 250/1000\n",
            " - 0s - loss: 0.0655 - val_loss: 0.0590\n",
            "Epoch 251/1000\n",
            " - 0s - loss: 0.0493 - val_loss: 0.0591\n",
            "Epoch 252/1000\n",
            " - 0s - loss: 0.0706 - val_loss: 0.0591\n",
            "Epoch 253/1000\n",
            " - 0s - loss: 0.1021 - val_loss: 0.0592\n",
            "Epoch 254/1000\n",
            " - 0s - loss: 0.0592 - val_loss: 0.0594\n",
            "Epoch 255/1000\n",
            " - 0s - loss: 0.0693 - val_loss: 0.0595\n",
            "Epoch 256/1000\n",
            " - 0s - loss: 0.0468 - val_loss: 0.0597\n",
            "Epoch 257/1000\n",
            " - 0s - loss: 0.0790 - val_loss: 0.0599\n",
            "Epoch 258/1000\n",
            " - 0s - loss: 0.0734 - val_loss: 0.0602\n",
            "Epoch 259/1000\n",
            " - 0s - loss: 0.0616 - val_loss: 0.0605\n",
            "Epoch 260/1000\n",
            " - 0s - loss: 0.0601 - val_loss: 0.0607\n",
            "Epoch 261/1000\n",
            " - 0s - loss: 0.0736 - val_loss: 0.0607\n",
            "Epoch 262/1000\n",
            " - 0s - loss: 0.0553 - val_loss: 0.0607\n",
            "Epoch 263/1000\n",
            " - 0s - loss: 0.0539 - val_loss: 0.0608\n",
            "Epoch 264/1000\n",
            " - 0s - loss: 0.0976 - val_loss: 0.0611\n",
            "Epoch 265/1000\n",
            " - 0s - loss: 0.0812 - val_loss: 0.0614\n",
            "Epoch 266/1000\n",
            " - 0s - loss: 0.0758 - val_loss: 0.0618\n",
            "Epoch 267/1000\n",
            " - 0s - loss: 0.0471 - val_loss: 0.0620\n",
            "Epoch 268/1000\n",
            " - 0s - loss: 0.0548 - val_loss: 0.0622\n",
            "Epoch 269/1000\n",
            " - 0s - loss: 0.0710 - val_loss: 0.0623\n",
            "Epoch 270/1000\n",
            " - 0s - loss: 0.0761 - val_loss: 0.0624\n",
            "Epoch 271/1000\n",
            " - 0s - loss: 0.1015 - val_loss: 0.0624\n",
            "Epoch 272/1000\n",
            " - 0s - loss: 0.0841 - val_loss: 0.0622\n",
            "Epoch 273/1000\n",
            " - 0s - loss: 0.0466 - val_loss: 0.0620\n",
            "Epoch 274/1000\n",
            " - 0s - loss: 0.1020 - val_loss: 0.0619\n",
            "Epoch 275/1000\n",
            " - 0s - loss: 0.0635 - val_loss: 0.0617\n",
            "Epoch 276/1000\n",
            " - 0s - loss: 0.0575 - val_loss: 0.0614\n",
            "Epoch 277/1000\n",
            " - 0s - loss: 0.0387 - val_loss: 0.0612\n",
            "Epoch 278/1000\n",
            " - 0s - loss: 0.0824 - val_loss: 0.0608\n",
            "Epoch 279/1000\n",
            " - 0s - loss: 0.0675 - val_loss: 0.0606\n",
            "Epoch 280/1000\n",
            " - 0s - loss: 0.0431 - val_loss: 0.0603\n",
            "Epoch 281/1000\n",
            " - 0s - loss: 0.0376 - val_loss: 0.0601\n",
            "Epoch 282/1000\n",
            " - 0s - loss: 0.0832 - val_loss: 0.0598\n",
            "Epoch 283/1000\n",
            " - 0s - loss: 0.0593 - val_loss: 0.0595\n",
            "Epoch 284/1000\n",
            " - 0s - loss: 0.0395 - val_loss: 0.0592\n",
            "Epoch 285/1000\n",
            " - 0s - loss: 0.0509 - val_loss: 0.0588\n",
            "Epoch 286/1000\n",
            " - 0s - loss: 0.0826 - val_loss: 0.0585\n",
            "Epoch 287/1000\n",
            " - 0s - loss: 0.0485 - val_loss: 0.0582\n",
            "Epoch 288/1000\n",
            " - 0s - loss: 0.0651 - val_loss: 0.0580\n",
            "Epoch 289/1000\n",
            " - 0s - loss: 0.0663 - val_loss: 0.0578\n",
            "Epoch 290/1000\n",
            " - 0s - loss: 0.0577 - val_loss: 0.0575\n",
            "Epoch 291/1000\n",
            " - 0s - loss: 0.0395 - val_loss: 0.0573\n",
            "Epoch 292/1000\n",
            " - 0s - loss: 0.0670 - val_loss: 0.0571\n",
            "Epoch 293/1000\n",
            " - 0s - loss: 0.0518 - val_loss: 0.0571\n",
            "Epoch 294/1000\n",
            " - 0s - loss: 0.0577 - val_loss: 0.0570\n",
            "Epoch 295/1000\n",
            " - 0s - loss: 0.0444 - val_loss: 0.0568\n",
            "Epoch 296/1000\n",
            " - 0s - loss: 0.0598 - val_loss: 0.0567\n",
            "Epoch 297/1000\n",
            " - 0s - loss: 0.0688 - val_loss: 0.0564\n",
            "Epoch 298/1000\n",
            " - 0s - loss: 0.0608 - val_loss: 0.0561\n",
            "Epoch 299/1000\n",
            " - 0s - loss: 0.0548 - val_loss: 0.0557\n",
            "Epoch 300/1000\n",
            " - 0s - loss: 0.0529 - val_loss: 0.0554\n",
            "Epoch 301/1000\n",
            " - 0s - loss: 0.0598 - val_loss: 0.0551\n",
            "Epoch 302/1000\n",
            " - 0s - loss: 0.0825 - val_loss: 0.0549\n",
            "Epoch 303/1000\n",
            " - 0s - loss: 0.0868 - val_loss: 0.0547\n",
            "Epoch 304/1000\n",
            " - 0s - loss: 0.0636 - val_loss: 0.0545\n",
            "Epoch 305/1000\n",
            " - 0s - loss: 0.0411 - val_loss: 0.0543\n",
            "Epoch 306/1000\n",
            " - 0s - loss: 0.0680 - val_loss: 0.0542\n",
            "Epoch 307/1000\n",
            " - 0s - loss: 0.0466 - val_loss: 0.0541\n",
            "Epoch 308/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0541\n",
            "Epoch 309/1000\n",
            " - 0s - loss: 0.0623 - val_loss: 0.0541\n",
            "Epoch 310/1000\n",
            " - 0s - loss: 0.0504 - val_loss: 0.0542\n",
            "Epoch 311/1000\n",
            " - 0s - loss: 0.0556 - val_loss: 0.0544\n",
            "Epoch 312/1000\n",
            " - 0s - loss: 0.0772 - val_loss: 0.0544\n",
            "Epoch 313/1000\n",
            " - 0s - loss: 0.0567 - val_loss: 0.0545\n",
            "Epoch 314/1000\n",
            " - 0s - loss: 0.0483 - val_loss: 0.0548\n",
            "Epoch 315/1000\n",
            " - 0s - loss: 0.0511 - val_loss: 0.0550\n",
            "Epoch 316/1000\n",
            " - 0s - loss: 0.0565 - val_loss: 0.0551\n",
            "Epoch 317/1000\n",
            " - 0s - loss: 0.0661 - val_loss: 0.0553\n",
            "Epoch 318/1000\n",
            " - 0s - loss: 0.0479 - val_loss: 0.0556\n",
            "Epoch 319/1000\n",
            " - 0s - loss: 0.0657 - val_loss: 0.0560\n",
            "Epoch 320/1000\n",
            " - 0s - loss: 0.0551 - val_loss: 0.0564\n",
            "Epoch 321/1000\n",
            " - 0s - loss: 0.0428 - val_loss: 0.0567\n",
            "Epoch 322/1000\n",
            " - 0s - loss: 0.0538 - val_loss: 0.0570\n",
            "Epoch 323/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0572\n",
            "Epoch 324/1000\n",
            " - 0s - loss: 0.0524 - val_loss: 0.0574\n",
            "Epoch 325/1000\n",
            " - 0s - loss: 0.0424 - val_loss: 0.0576\n",
            "Epoch 326/1000\n",
            " - 0s - loss: 0.0604 - val_loss: 0.0578\n",
            "Epoch 327/1000\n",
            " - 0s - loss: 0.0451 - val_loss: 0.0581\n",
            "Epoch 328/1000\n",
            " - 0s - loss: 0.0673 - val_loss: 0.0583\n",
            "Epoch 329/1000\n",
            " - 0s - loss: 0.0743 - val_loss: 0.0585\n",
            "Epoch 330/1000\n",
            " - 0s - loss: 0.0540 - val_loss: 0.0587\n",
            "Epoch 331/1000\n",
            " - 0s - loss: 0.0579 - val_loss: 0.0589\n",
            "Epoch 332/1000\n",
            " - 0s - loss: 0.0735 - val_loss: 0.0590\n",
            "Epoch 333/1000\n",
            " - 0s - loss: 0.0703 - val_loss: 0.0590\n",
            "Epoch 334/1000\n",
            " - 0s - loss: 0.0565 - val_loss: 0.0590\n",
            "Epoch 335/1000\n",
            " - 0s - loss: 0.0640 - val_loss: 0.0591\n",
            "Epoch 336/1000\n",
            " - 0s - loss: 0.0374 - val_loss: 0.0592\n",
            "Epoch 337/1000\n",
            " - 0s - loss: 0.0460 - val_loss: 0.0593\n",
            "Epoch 338/1000\n",
            " - 0s - loss: 0.0587 - val_loss: 0.0594\n",
            "Epoch 339/1000\n",
            " - 0s - loss: 0.0548 - val_loss: 0.0594\n",
            "Epoch 340/1000\n",
            " - 0s - loss: 0.0394 - val_loss: 0.0594\n",
            "Epoch 341/1000\n",
            " - 0s - loss: 0.0539 - val_loss: 0.0595\n",
            "Epoch 342/1000\n",
            " - 0s - loss: 0.0734 - val_loss: 0.0597\n",
            "Epoch 343/1000\n",
            " - 0s - loss: 0.0543 - val_loss: 0.0599\n",
            "Epoch 344/1000\n",
            " - 0s - loss: 0.0506 - val_loss: 0.0600\n",
            "Epoch 345/1000\n",
            " - 0s - loss: 0.0635 - val_loss: 0.0601\n",
            "Epoch 346/1000\n",
            " - 0s - loss: 0.0443 - val_loss: 0.0603\n",
            "Epoch 347/1000\n",
            " - 0s - loss: 0.0838 - val_loss: 0.0605\n",
            "Epoch 348/1000\n",
            " - 0s - loss: 0.0524 - val_loss: 0.0606\n",
            "Epoch 349/1000\n",
            " - 0s - loss: 0.0293 - val_loss: 0.0606\n",
            "Epoch 350/1000\n",
            " - 0s - loss: 0.0394 - val_loss: 0.0605\n",
            "Epoch 351/1000\n",
            " - 0s - loss: 0.0493 - val_loss: 0.0604\n",
            "Epoch 352/1000\n",
            " - 0s - loss: 0.0607 - val_loss: 0.0604\n",
            "Epoch 353/1000\n",
            " - 0s - loss: 0.0473 - val_loss: 0.0603\n",
            "Epoch 354/1000\n",
            " - 0s - loss: 0.0535 - val_loss: 0.0604\n",
            "Epoch 355/1000\n",
            " - 0s - loss: 0.0479 - val_loss: 0.0605\n",
            "Epoch 356/1000\n",
            " - 0s - loss: 0.0576 - val_loss: 0.0606\n",
            "Epoch 357/1000\n",
            " - 0s - loss: 0.0284 - val_loss: 0.0607\n",
            "Epoch 358/1000\n",
            " - 0s - loss: 0.0433 - val_loss: 0.0607\n",
            "Epoch 359/1000\n",
            " - 0s - loss: 0.0479 - val_loss: 0.0606\n",
            "Epoch 360/1000\n",
            " - 0s - loss: 0.0724 - val_loss: 0.0606\n",
            "Epoch 361/1000\n",
            " - 0s - loss: 0.0556 - val_loss: 0.0606\n",
            "Epoch 362/1000\n",
            " - 0s - loss: 0.0365 - val_loss: 0.0607\n",
            "Epoch 363/1000\n",
            " - 0s - loss: 0.0418 - val_loss: 0.0608\n",
            "Epoch 364/1000\n",
            " - 0s - loss: 0.0441 - val_loss: 0.0610\n",
            "Epoch 365/1000\n",
            " - 0s - loss: 0.0359 - val_loss: 0.0612\n",
            "Epoch 366/1000\n",
            " - 0s - loss: 0.0718 - val_loss: 0.0613\n",
            "Epoch 367/1000\n",
            " - 0s - loss: 0.0482 - val_loss: 0.0613\n",
            "Epoch 368/1000\n",
            " - 0s - loss: 0.0510 - val_loss: 0.0612\n",
            "Epoch 369/1000\n",
            " - 0s - loss: 0.0782 - val_loss: 0.0612\n",
            "Epoch 370/1000\n",
            " - 0s - loss: 0.0601 - val_loss: 0.0610\n",
            "Epoch 371/1000\n",
            " - 0s - loss: 0.0507 - val_loss: 0.0609\n",
            "Epoch 372/1000\n",
            " - 0s - loss: 0.0523 - val_loss: 0.0609\n",
            "Epoch 373/1000\n",
            " - 0s - loss: 0.0629 - val_loss: 0.0609\n",
            "Epoch 374/1000\n",
            " - 0s - loss: 0.0498 - val_loss: 0.0609\n",
            "Epoch 375/1000\n",
            " - 0s - loss: 0.0499 - val_loss: 0.0607\n",
            "Epoch 376/1000\n",
            " - 0s - loss: 0.0406 - val_loss: 0.0605\n",
            "Epoch 377/1000\n",
            " - 0s - loss: 0.0613 - val_loss: 0.0602\n",
            "Epoch 378/1000\n",
            " - 0s - loss: 0.0511 - val_loss: 0.0602\n",
            "Epoch 379/1000\n",
            " - 0s - loss: 0.0555 - val_loss: 0.0602\n",
            "Epoch 380/1000\n",
            " - 0s - loss: 0.0535 - val_loss: 0.0602\n",
            "Epoch 381/1000\n",
            " - 0s - loss: 0.0401 - val_loss: 0.0602\n",
            "Epoch 382/1000\n",
            " - 0s - loss: 0.0474 - val_loss: 0.0603\n",
            "Epoch 383/1000\n",
            " - 0s - loss: 0.0530 - val_loss: 0.0605\n",
            "Epoch 384/1000\n",
            " - 0s - loss: 0.0513 - val_loss: 0.0608\n",
            "Epoch 385/1000\n",
            " - 0s - loss: 0.0419 - val_loss: 0.0612\n",
            "Epoch 386/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0616\n",
            "Epoch 387/1000\n",
            " - 0s - loss: 0.0612 - val_loss: 0.0620\n",
            "Epoch 388/1000\n",
            " - 0s - loss: 0.0485 - val_loss: 0.0625\n",
            "Epoch 389/1000\n",
            " - 0s - loss: 0.0812 - val_loss: 0.0630\n",
            "Epoch 390/1000\n",
            " - 0s - loss: 0.0489 - val_loss: 0.0634\n",
            "Epoch 391/1000\n",
            " - 0s - loss: 0.0535 - val_loss: 0.0636\n",
            "Epoch 392/1000\n",
            " - 0s - loss: 0.0372 - val_loss: 0.0639\n",
            "Epoch 393/1000\n",
            " - 0s - loss: 0.0519 - val_loss: 0.0640\n",
            "Epoch 394/1000\n",
            " - 0s - loss: 0.0448 - val_loss: 0.0640\n",
            "Epoch 395/1000\n",
            " - 0s - loss: 0.0423 - val_loss: 0.0640\n",
            "Epoch 396/1000\n",
            " - 0s - loss: 0.0396 - val_loss: 0.0641\n",
            "Epoch 397/1000\n",
            " - 0s - loss: 0.0389 - val_loss: 0.0641\n",
            "Epoch 398/1000\n",
            " - 0s - loss: 0.0359 - val_loss: 0.0641\n",
            "Epoch 399/1000\n",
            " - 0s - loss: 0.0419 - val_loss: 0.0641\n",
            "Epoch 400/1000\n",
            " - 0s - loss: 0.0278 - val_loss: 0.0640\n",
            "Epoch 401/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0639\n",
            "Epoch 402/1000\n",
            " - 0s - loss: 0.0397 - val_loss: 0.0638\n",
            "Epoch 403/1000\n",
            " - 0s - loss: 0.0476 - val_loss: 0.0637\n",
            "Epoch 404/1000\n",
            " - 0s - loss: 0.0523 - val_loss: 0.0633\n",
            "Epoch 405/1000\n",
            " - 0s - loss: 0.0400 - val_loss: 0.0630\n",
            "Epoch 406/1000\n",
            " - 0s - loss: 0.0453 - val_loss: 0.0628\n",
            "Epoch 407/1000\n",
            " - 0s - loss: 0.0533 - val_loss: 0.0625\n",
            "Epoch 408/1000\n",
            " - 0s - loss: 0.0557 - val_loss: 0.0622\n",
            "Epoch 409/1000\n",
            " - 0s - loss: 0.0476 - val_loss: 0.0619\n",
            "Epoch 410/1000\n",
            " - 0s - loss: 0.0665 - val_loss: 0.0619\n",
            "Epoch 411/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0619\n",
            "Epoch 412/1000\n",
            " - 0s - loss: 0.0518 - val_loss: 0.0619\n",
            "Epoch 413/1000\n",
            " - 0s - loss: 0.0644 - val_loss: 0.0620\n",
            "Epoch 414/1000\n",
            " - 0s - loss: 0.0525 - val_loss: 0.0621\n",
            "Epoch 415/1000\n",
            " - 0s - loss: 0.0374 - val_loss: 0.0622\n",
            "Epoch 416/1000\n",
            " - 0s - loss: 0.0547 - val_loss: 0.0625\n",
            "Epoch 417/1000\n",
            " - 0s - loss: 0.0586 - val_loss: 0.0627\n",
            "Epoch 418/1000\n",
            " - 0s - loss: 0.0955 - val_loss: 0.0629\n",
            "Epoch 419/1000\n",
            " - 0s - loss: 0.0504 - val_loss: 0.0632\n",
            "Epoch 420/1000\n",
            " - 0s - loss: 0.0815 - val_loss: 0.0634\n",
            "Epoch 421/1000\n",
            " - 0s - loss: 0.0396 - val_loss: 0.0636\n",
            "Epoch 422/1000\n",
            " - 0s - loss: 0.0465 - val_loss: 0.0639\n",
            "Epoch 423/1000\n",
            " - 0s - loss: 0.0600 - val_loss: 0.0643\n",
            "Epoch 424/1000\n",
            " - 0s - loss: 0.0489 - val_loss: 0.0646\n",
            "Epoch 425/1000\n",
            " - 0s - loss: 0.0549 - val_loss: 0.0650\n",
            "Epoch 426/1000\n",
            " - 0s - loss: 0.0288 - val_loss: 0.0654\n",
            "Epoch 427/1000\n",
            " - 0s - loss: 0.0594 - val_loss: 0.0658\n",
            "Epoch 428/1000\n",
            " - 0s - loss: 0.0499 - val_loss: 0.0662\n",
            "Epoch 429/1000\n",
            " - 0s - loss: 0.0402 - val_loss: 0.0666\n",
            "Epoch 430/1000\n",
            " - 0s - loss: 0.0422 - val_loss: 0.0669\n",
            "Epoch 431/1000\n",
            " - 0s - loss: 0.0340 - val_loss: 0.0672\n",
            "Epoch 432/1000\n",
            " - 0s - loss: 0.0478 - val_loss: 0.0675\n",
            "Epoch 433/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0678\n",
            "Epoch 434/1000\n",
            " - 0s - loss: 0.0429 - val_loss: 0.0681\n",
            "Epoch 435/1000\n",
            " - 0s - loss: 0.0506 - val_loss: 0.0682\n",
            "Epoch 436/1000\n",
            " - 0s - loss: 0.0455 - val_loss: 0.0684\n",
            "Epoch 437/1000\n",
            " - 0s - loss: 0.0538 - val_loss: 0.0684\n",
            "Epoch 438/1000\n",
            " - 0s - loss: 0.0464 - val_loss: 0.0685\n",
            "Epoch 439/1000\n",
            " - 0s - loss: 0.0405 - val_loss: 0.0687\n",
            "Epoch 440/1000\n",
            " - 0s - loss: 0.0319 - val_loss: 0.0687\n",
            "Epoch 441/1000\n",
            " - 0s - loss: 0.0294 - val_loss: 0.0689\n",
            "Epoch 442/1000\n",
            " - 0s - loss: 0.0436 - val_loss: 0.0690\n",
            "Epoch 443/1000\n",
            " - 0s - loss: 0.0252 - val_loss: 0.0690\n",
            "Epoch 444/1000\n",
            " - 0s - loss: 0.0680 - val_loss: 0.0690\n",
            "Epoch 445/1000\n",
            " - 0s - loss: 0.0674 - val_loss: 0.0689\n",
            "Epoch 446/1000\n",
            " - 0s - loss: 0.0623 - val_loss: 0.0688\n",
            "Epoch 447/1000\n",
            " - 0s - loss: 0.0460 - val_loss: 0.0688\n",
            "Epoch 448/1000\n",
            " - 0s - loss: 0.0697 - val_loss: 0.0689\n",
            "Epoch 449/1000\n",
            " - 0s - loss: 0.0395 - val_loss: 0.0690\n",
            "Epoch 450/1000\n",
            " - 0s - loss: 0.0438 - val_loss: 0.0689\n",
            "Epoch 451/1000\n",
            " - 0s - loss: 0.0331 - val_loss: 0.0689\n",
            "Epoch 452/1000\n",
            " - 0s - loss: 0.0364 - val_loss: 0.0689\n",
            "Epoch 453/1000\n",
            " - 0s - loss: 0.0391 - val_loss: 0.0690\n",
            "Epoch 454/1000\n",
            " - 0s - loss: 0.0358 - val_loss: 0.0691\n",
            "Epoch 455/1000\n",
            " - 0s - loss: 0.0515 - val_loss: 0.0692\n",
            "Epoch 456/1000\n",
            " - 0s - loss: 0.0352 - val_loss: 0.0692\n",
            "Epoch 457/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0691\n",
            "Epoch 458/1000\n",
            " - 0s - loss: 0.0426 - val_loss: 0.0688\n",
            "Epoch 459/1000\n",
            " - 0s - loss: 0.0270 - val_loss: 0.0686\n",
            "Epoch 460/1000\n",
            " - 0s - loss: 0.0415 - val_loss: 0.0684\n",
            "Epoch 461/1000\n",
            " - 0s - loss: 0.0563 - val_loss: 0.0681\n",
            "Epoch 462/1000\n",
            " - 0s - loss: 0.0345 - val_loss: 0.0677\n",
            "Epoch 463/1000\n",
            " - 0s - loss: 0.0474 - val_loss: 0.0675\n",
            "Epoch 464/1000\n",
            " - 0s - loss: 0.0658 - val_loss: 0.0674\n",
            "Epoch 465/1000\n",
            " - 0s - loss: 0.0568 - val_loss: 0.0674\n",
            "Epoch 466/1000\n",
            " - 0s - loss: 0.0421 - val_loss: 0.0675\n",
            "Epoch 467/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0676\n",
            "Epoch 468/1000\n",
            " - 0s - loss: 0.0370 - val_loss: 0.0677\n",
            "Epoch 469/1000\n",
            " - 0s - loss: 0.0557 - val_loss: 0.0679\n",
            "Epoch 470/1000\n",
            " - 0s - loss: 0.0833 - val_loss: 0.0680\n",
            "Epoch 471/1000\n",
            " - 0s - loss: 0.0430 - val_loss: 0.0681\n",
            "Epoch 472/1000\n",
            " - 0s - loss: 0.0640 - val_loss: 0.0681\n",
            "Epoch 473/1000\n",
            " - 0s - loss: 0.0447 - val_loss: 0.0682\n",
            "Epoch 474/1000\n",
            " - 0s - loss: 0.0389 - val_loss: 0.0681\n",
            "Epoch 475/1000\n",
            " - 0s - loss: 0.0499 - val_loss: 0.0683\n",
            "Epoch 476/1000\n",
            " - 0s - loss: 0.0301 - val_loss: 0.0685\n",
            "Epoch 477/1000\n",
            " - 0s - loss: 0.0455 - val_loss: 0.0686\n",
            "Epoch 478/1000\n",
            " - 0s - loss: 0.0511 - val_loss: 0.0686\n",
            "Epoch 479/1000\n",
            " - 0s - loss: 0.0506 - val_loss: 0.0688\n",
            "Epoch 480/1000\n",
            " - 0s - loss: 0.0393 - val_loss: 0.0692\n",
            "Epoch 481/1000\n",
            " - 0s - loss: 0.0592 - val_loss: 0.0693\n",
            "Epoch 482/1000\n",
            " - 0s - loss: 0.0309 - val_loss: 0.0696\n",
            "Epoch 483/1000\n",
            " - 0s - loss: 0.0659 - val_loss: 0.0699\n",
            "Epoch 484/1000\n",
            " - 0s - loss: 0.0507 - val_loss: 0.0702\n",
            "Epoch 485/1000\n",
            " - 0s - loss: 0.0522 - val_loss: 0.0706\n",
            "Epoch 486/1000\n",
            " - 0s - loss: 0.0416 - val_loss: 0.0709\n",
            "Epoch 487/1000\n",
            " - 0s - loss: 0.0333 - val_loss: 0.0712\n",
            "Epoch 488/1000\n",
            " - 0s - loss: 0.0404 - val_loss: 0.0713\n",
            "Epoch 489/1000\n",
            " - 0s - loss: 0.0616 - val_loss: 0.0713\n",
            "Epoch 490/1000\n",
            " - 0s - loss: 0.0576 - val_loss: 0.0713\n",
            "Epoch 491/1000\n",
            " - 0s - loss: 0.0527 - val_loss: 0.0713\n",
            "Epoch 492/1000\n",
            " - 0s - loss: 0.0367 - val_loss: 0.0714\n",
            "Epoch 493/1000\n",
            " - 0s - loss: 0.0514 - val_loss: 0.0713\n",
            "Epoch 494/1000\n",
            " - 0s - loss: 0.0652 - val_loss: 0.0712\n",
            "Epoch 495/1000\n",
            " - 0s - loss: 0.0608 - val_loss: 0.0711\n",
            "Epoch 496/1000\n",
            " - 0s - loss: 0.0543 - val_loss: 0.0712\n",
            "Epoch 497/1000\n",
            " - 0s - loss: 0.0411 - val_loss: 0.0711\n",
            "Epoch 498/1000\n",
            " - 0s - loss: 0.0494 - val_loss: 0.0710\n",
            "Epoch 499/1000\n",
            " - 0s - loss: 0.0335 - val_loss: 0.0711\n",
            "Epoch 500/1000\n",
            " - 0s - loss: 0.0610 - val_loss: 0.0713\n",
            "Epoch 501/1000\n",
            " - 0s - loss: 0.0994 - val_loss: 0.0715\n",
            "Epoch 502/1000\n",
            " - 0s - loss: 0.0438 - val_loss: 0.0716\n",
            "Epoch 503/1000\n",
            " - 0s - loss: 0.0367 - val_loss: 0.0718\n",
            "Epoch 504/1000\n",
            " - 0s - loss: 0.0571 - val_loss: 0.0718\n",
            "Epoch 505/1000\n",
            " - 0s - loss: 0.0521 - val_loss: 0.0719\n",
            "Epoch 506/1000\n",
            " - 0s - loss: 0.0466 - val_loss: 0.0721\n",
            "Epoch 507/1000\n",
            " - 0s - loss: 0.0454 - val_loss: 0.0724\n",
            "Epoch 508/1000\n",
            " - 0s - loss: 0.0565 - val_loss: 0.0727\n",
            "Epoch 509/1000\n",
            " - 0s - loss: 0.0635 - val_loss: 0.0729\n",
            "Epoch 510/1000\n",
            " - 0s - loss: 0.0403 - val_loss: 0.0731\n",
            "Epoch 511/1000\n",
            " - 0s - loss: 0.0550 - val_loss: 0.0734\n",
            "Epoch 512/1000\n",
            " - 0s - loss: 0.0413 - val_loss: 0.0738\n",
            "Epoch 513/1000\n",
            " - 0s - loss: 0.0462 - val_loss: 0.0742\n",
            "Epoch 514/1000\n",
            " - 0s - loss: 0.0610 - val_loss: 0.0747\n",
            "Epoch 515/1000\n",
            " - 0s - loss: 0.0743 - val_loss: 0.0751\n",
            "Epoch 516/1000\n",
            " - 0s - loss: 0.0414 - val_loss: 0.0754\n",
            "Epoch 517/1000\n",
            " - 0s - loss: 0.0336 - val_loss: 0.0758\n",
            "Epoch 518/1000\n",
            " - 0s - loss: 0.0634 - val_loss: 0.0763\n",
            "Epoch 519/1000\n",
            " - 0s - loss: 0.0341 - val_loss: 0.0768\n",
            "Epoch 520/1000\n",
            " - 0s - loss: 0.0491 - val_loss: 0.0772\n",
            "Epoch 521/1000\n",
            " - 0s - loss: 0.0339 - val_loss: 0.0775\n",
            "Epoch 522/1000\n",
            " - 0s - loss: 0.0440 - val_loss: 0.0777\n",
            "Epoch 523/1000\n",
            " - 0s - loss: 0.0430 - val_loss: 0.0778\n",
            "Epoch 524/1000\n",
            " - 0s - loss: 0.0405 - val_loss: 0.0781\n",
            "Epoch 525/1000\n",
            " - 0s - loss: 0.0392 - val_loss: 0.0783\n",
            "Epoch 526/1000\n",
            " - 0s - loss: 0.0541 - val_loss: 0.0784\n",
            "Epoch 527/1000\n",
            " - 0s - loss: 0.0378 - val_loss: 0.0784\n",
            "Epoch 528/1000\n",
            " - 0s - loss: 0.0295 - val_loss: 0.0785\n",
            "Epoch 529/1000\n",
            " - 0s - loss: 0.0701 - val_loss: 0.0787\n",
            "Epoch 530/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0789\n",
            "Epoch 531/1000\n",
            " - 0s - loss: 0.0457 - val_loss: 0.0792\n",
            "Epoch 532/1000\n",
            " - 0s - loss: 0.0560 - val_loss: 0.0795\n",
            "Epoch 533/1000\n",
            " - 0s - loss: 0.0403 - val_loss: 0.0797\n",
            "Epoch 534/1000\n",
            " - 0s - loss: 0.0481 - val_loss: 0.0799\n",
            "Epoch 535/1000\n",
            " - 0s - loss: 0.0509 - val_loss: 0.0801\n",
            "Epoch 536/1000\n",
            " - 0s - loss: 0.0525 - val_loss: 0.0802\n",
            "Epoch 537/1000\n",
            " - 0s - loss: 0.0447 - val_loss: 0.0802\n",
            "Epoch 538/1000\n",
            " - 0s - loss: 0.0420 - val_loss: 0.0799\n",
            "Epoch 539/1000\n",
            " - 0s - loss: 0.0347 - val_loss: 0.0798\n",
            "Epoch 540/1000\n",
            " - 0s - loss: 0.0453 - val_loss: 0.0796\n",
            "Epoch 541/1000\n",
            " - 0s - loss: 0.0355 - val_loss: 0.0793\n",
            "Epoch 542/1000\n",
            " - 0s - loss: 0.0559 - val_loss: 0.0791\n",
            "Epoch 543/1000\n",
            " - 0s - loss: 0.0551 - val_loss: 0.0787\n",
            "Epoch 544/1000\n",
            " - 0s - loss: 0.0366 - val_loss: 0.0784\n",
            "Epoch 545/1000\n",
            " - 0s - loss: 0.0397 - val_loss: 0.0780\n",
            "Epoch 546/1000\n",
            " - 0s - loss: 0.0279 - val_loss: 0.0776\n",
            "Epoch 547/1000\n",
            " - 0s - loss: 0.0312 - val_loss: 0.0772\n",
            "Epoch 548/1000\n",
            " - 0s - loss: 0.0586 - val_loss: 0.0767\n",
            "Epoch 549/1000\n",
            " - 0s - loss: 0.0514 - val_loss: 0.0763\n",
            "Epoch 550/1000\n",
            " - 0s - loss: 0.0306 - val_loss: 0.0760\n",
            "Epoch 551/1000\n",
            " - 0s - loss: 0.0494 - val_loss: 0.0758\n",
            "Epoch 552/1000\n",
            " - 0s - loss: 0.0275 - val_loss: 0.0757\n",
            "Epoch 553/1000\n",
            " - 0s - loss: 0.0471 - val_loss: 0.0755\n",
            "Epoch 554/1000\n",
            " - 0s - loss: 0.0230 - val_loss: 0.0754\n",
            "Epoch 555/1000\n",
            " - 0s - loss: 0.0396 - val_loss: 0.0754\n",
            "Epoch 556/1000\n",
            " - 0s - loss: 0.0274 - val_loss: 0.0754\n",
            "Epoch 557/1000\n",
            " - 0s - loss: 0.0449 - val_loss: 0.0755\n",
            "Epoch 558/1000\n",
            " - 0s - loss: 0.0565 - val_loss: 0.0754\n",
            "Epoch 559/1000\n",
            " - 0s - loss: 0.0581 - val_loss: 0.0753\n",
            "Epoch 560/1000\n",
            " - 0s - loss: 0.0286 - val_loss: 0.0752\n",
            "Epoch 561/1000\n",
            " - 0s - loss: 0.0405 - val_loss: 0.0751\n",
            "Epoch 562/1000\n",
            " - 0s - loss: 0.0280 - val_loss: 0.0750\n",
            "Epoch 563/1000\n",
            " - 0s - loss: 0.0630 - val_loss: 0.0750\n",
            "Epoch 564/1000\n",
            " - 0s - loss: 0.0691 - val_loss: 0.0749\n",
            "Epoch 565/1000\n",
            " - 0s - loss: 0.0474 - val_loss: 0.0749\n",
            "Epoch 566/1000\n",
            " - 0s - loss: 0.0291 - val_loss: 0.0750\n",
            "Epoch 567/1000\n",
            " - 0s - loss: 0.0294 - val_loss: 0.0750\n",
            "Epoch 568/1000\n",
            " - 0s - loss: 0.0427 - val_loss: 0.0750\n",
            "Epoch 569/1000\n",
            " - 0s - loss: 0.0349 - val_loss: 0.0750\n",
            "Epoch 570/1000\n",
            " - 0s - loss: 0.0249 - val_loss: 0.0750\n",
            "Epoch 571/1000\n",
            " - 0s - loss: 0.0285 - val_loss: 0.0750\n",
            "Epoch 572/1000\n",
            " - 0s - loss: 0.0363 - val_loss: 0.0751\n",
            "Epoch 573/1000\n",
            " - 0s - loss: 0.0457 - val_loss: 0.0751\n",
            "Epoch 574/1000\n",
            " - 0s - loss: 0.0250 - val_loss: 0.0751\n",
            "Epoch 575/1000\n",
            " - 0s - loss: 0.0495 - val_loss: 0.0753\n",
            "Epoch 576/1000\n",
            " - 0s - loss: 0.0367 - val_loss: 0.0755\n",
            "Epoch 577/1000\n",
            " - 0s - loss: 0.0314 - val_loss: 0.0758\n",
            "Epoch 578/1000\n",
            " - 0s - loss: 0.0265 - val_loss: 0.0760\n",
            "Epoch 579/1000\n",
            " - 0s - loss: 0.0336 - val_loss: 0.0763\n",
            "Epoch 580/1000\n",
            " - 0s - loss: 0.0267 - val_loss: 0.0766\n",
            "Epoch 581/1000\n",
            " - 0s - loss: 0.0594 - val_loss: 0.0769\n",
            "Epoch 582/1000\n",
            " - 0s - loss: 0.0408 - val_loss: 0.0773\n",
            "Epoch 583/1000\n",
            " - 0s - loss: 0.0545 - val_loss: 0.0777\n",
            "Epoch 584/1000\n",
            " - 0s - loss: 0.0364 - val_loss: 0.0781\n",
            "Epoch 585/1000\n",
            " - 0s - loss: 0.0367 - val_loss: 0.0782\n",
            "Epoch 586/1000\n",
            " - 0s - loss: 0.0655 - val_loss: 0.0781\n",
            "Epoch 587/1000\n",
            " - 0s - loss: 0.0272 - val_loss: 0.0781\n",
            "Epoch 588/1000\n",
            " - 0s - loss: 0.0455 - val_loss: 0.0780\n",
            "Epoch 589/1000\n",
            " - 0s - loss: 0.0654 - val_loss: 0.0778\n",
            "Epoch 590/1000\n",
            " - 0s - loss: 0.0655 - val_loss: 0.0776\n",
            "Epoch 591/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0775\n",
            "Epoch 592/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0776\n",
            "Epoch 593/1000\n",
            " - 0s - loss: 0.0307 - val_loss: 0.0777\n",
            "Epoch 594/1000\n",
            " - 0s - loss: 0.0427 - val_loss: 0.0779\n",
            "Epoch 595/1000\n",
            " - 0s - loss: 0.0416 - val_loss: 0.0779\n",
            "Epoch 596/1000\n",
            " - 0s - loss: 0.0418 - val_loss: 0.0779\n",
            "Epoch 597/1000\n",
            " - 0s - loss: 0.0439 - val_loss: 0.0778\n",
            "Epoch 598/1000\n",
            " - 0s - loss: 0.0434 - val_loss: 0.0776\n",
            "Epoch 599/1000\n",
            " - 0s - loss: 0.0519 - val_loss: 0.0773\n",
            "Epoch 600/1000\n",
            " - 0s - loss: 0.0330 - val_loss: 0.0772\n",
            "Epoch 601/1000\n",
            " - 0s - loss: 0.0353 - val_loss: 0.0771\n",
            "Epoch 602/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0771\n",
            "Epoch 603/1000\n",
            " - 0s - loss: 0.0249 - val_loss: 0.0771\n",
            "Epoch 604/1000\n",
            " - 0s - loss: 0.0459 - val_loss: 0.0770\n",
            "Epoch 605/1000\n",
            " - 0s - loss: 0.0663 - val_loss: 0.0770\n",
            "Epoch 606/1000\n",
            " - 0s - loss: 0.0226 - val_loss: 0.0768\n",
            "Epoch 607/1000\n",
            " - 0s - loss: 0.0526 - val_loss: 0.0766\n",
            "Epoch 608/1000\n",
            " - 0s - loss: 0.0411 - val_loss: 0.0764\n",
            "Epoch 609/1000\n",
            " - 0s - loss: 0.0516 - val_loss: 0.0762\n",
            "Epoch 610/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0759\n",
            "Epoch 611/1000\n",
            " - 0s - loss: 0.0460 - val_loss: 0.0757\n",
            "Epoch 612/1000\n",
            " - 0s - loss: 0.0680 - val_loss: 0.0754\n",
            "Epoch 613/1000\n",
            " - 0s - loss: 0.0275 - val_loss: 0.0753\n",
            "Epoch 614/1000\n",
            " - 0s - loss: 0.0425 - val_loss: 0.0751\n",
            "Epoch 615/1000\n",
            " - 0s - loss: 0.0471 - val_loss: 0.0749\n",
            "Epoch 616/1000\n",
            " - 0s - loss: 0.0710 - val_loss: 0.0748\n",
            "Epoch 617/1000\n",
            " - 0s - loss: 0.0546 - val_loss: 0.0747\n",
            "Epoch 618/1000\n",
            " - 0s - loss: 0.0305 - val_loss: 0.0747\n",
            "Epoch 619/1000\n",
            " - 0s - loss: 0.0454 - val_loss: 0.0749\n",
            "Epoch 620/1000\n",
            " - 0s - loss: 0.0375 - val_loss: 0.0753\n",
            "Epoch 621/1000\n",
            " - 0s - loss: 0.0672 - val_loss: 0.0757\n",
            "Epoch 622/1000\n",
            " - 0s - loss: 0.0447 - val_loss: 0.0760\n",
            "Epoch 623/1000\n",
            " - 0s - loss: 0.0427 - val_loss: 0.0766\n",
            "Epoch 624/1000\n",
            " - 0s - loss: 0.0356 - val_loss: 0.0770\n",
            "Epoch 625/1000\n",
            " - 0s - loss: 0.0443 - val_loss: 0.0773\n",
            "Epoch 626/1000\n",
            " - 0s - loss: 0.0424 - val_loss: 0.0776\n",
            "Epoch 627/1000\n",
            " - 0s - loss: 0.0379 - val_loss: 0.0780\n",
            "Epoch 628/1000\n",
            " - 0s - loss: 0.0404 - val_loss: 0.0784\n",
            "Epoch 629/1000\n",
            " - 0s - loss: 0.0331 - val_loss: 0.0788\n",
            "Epoch 630/1000\n",
            " - 0s - loss: 0.0453 - val_loss: 0.0792\n",
            "Epoch 631/1000\n",
            " - 0s - loss: 0.0236 - val_loss: 0.0797\n",
            "Epoch 632/1000\n",
            " - 0s - loss: 0.0343 - val_loss: 0.0802\n",
            "Epoch 633/1000\n",
            " - 0s - loss: 0.0333 - val_loss: 0.0807\n",
            "Epoch 634/1000\n",
            " - 0s - loss: 0.0381 - val_loss: 0.0811\n",
            "Epoch 635/1000\n",
            " - 0s - loss: 0.0386 - val_loss: 0.0816\n",
            "Epoch 636/1000\n",
            " - 0s - loss: 0.0642 - val_loss: 0.0819\n",
            "Epoch 637/1000\n",
            " - 0s - loss: 0.0347 - val_loss: 0.0821\n",
            "Epoch 638/1000\n",
            " - 0s - loss: 0.0327 - val_loss: 0.0823\n",
            "Epoch 639/1000\n",
            " - 0s - loss: 0.0447 - val_loss: 0.0826\n",
            "Epoch 640/1000\n",
            " - 0s - loss: 0.0306 - val_loss: 0.0828\n",
            "Epoch 641/1000\n",
            " - 0s - loss: 0.0359 - val_loss: 0.0828\n",
            "Epoch 642/1000\n",
            " - 0s - loss: 0.0470 - val_loss: 0.0827\n",
            "Epoch 643/1000\n",
            " - 0s - loss: 0.0329 - val_loss: 0.0824\n",
            "Epoch 644/1000\n",
            " - 0s - loss: 0.0317 - val_loss: 0.0821\n",
            "Epoch 645/1000\n",
            " - 0s - loss: 0.0381 - val_loss: 0.0818\n",
            "Epoch 646/1000\n",
            " - 0s - loss: 0.0514 - val_loss: 0.0813\n",
            "Epoch 647/1000\n",
            " - 0s - loss: 0.0470 - val_loss: 0.0808\n",
            "Epoch 648/1000\n",
            " - 0s - loss: 0.0563 - val_loss: 0.0803\n",
            "Epoch 649/1000\n",
            " - 0s - loss: 0.0210 - val_loss: 0.0799\n",
            "Epoch 650/1000\n",
            " - 0s - loss: 0.0352 - val_loss: 0.0795\n",
            "Epoch 651/1000\n",
            " - 0s - loss: 0.0414 - val_loss: 0.0793\n",
            "Epoch 652/1000\n",
            " - 0s - loss: 0.0636 - val_loss: 0.0790\n",
            "Epoch 653/1000\n",
            " - 0s - loss: 0.0426 - val_loss: 0.0788\n",
            "Epoch 654/1000\n",
            " - 0s - loss: 0.0609 - val_loss: 0.0788\n",
            "Epoch 655/1000\n",
            " - 0s - loss: 0.0536 - val_loss: 0.0786\n",
            "Epoch 656/1000\n",
            " - 0s - loss: 0.0279 - val_loss: 0.0785\n",
            "Epoch 657/1000\n",
            " - 0s - loss: 0.0541 - val_loss: 0.0783\n",
            "Epoch 658/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0782\n",
            "Epoch 659/1000\n",
            " - 0s - loss: 0.0320 - val_loss: 0.0784\n",
            "Epoch 660/1000\n",
            " - 0s - loss: 0.0355 - val_loss: 0.0785\n",
            "Epoch 661/1000\n",
            " - 0s - loss: 0.0378 - val_loss: 0.0786\n",
            "Epoch 662/1000\n",
            " - 0s - loss: 0.0649 - val_loss: 0.0786\n",
            "Epoch 663/1000\n",
            " - 0s - loss: 0.0401 - val_loss: 0.0788\n",
            "Epoch 664/1000\n",
            " - 0s - loss: 0.0273 - val_loss: 0.0790\n",
            "Epoch 665/1000\n",
            " - 0s - loss: 0.0321 - val_loss: 0.0793\n",
            "Epoch 666/1000\n",
            " - 0s - loss: 0.0402 - val_loss: 0.0797\n",
            "Epoch 667/1000\n",
            " - 0s - loss: 0.0298 - val_loss: 0.0801\n",
            "Epoch 668/1000\n",
            " - 0s - loss: 0.0448 - val_loss: 0.0804\n",
            "Epoch 669/1000\n",
            " - 0s - loss: 0.0517 - val_loss: 0.0807\n",
            "Epoch 670/1000\n",
            " - 0s - loss: 0.0557 - val_loss: 0.0811\n",
            "Epoch 671/1000\n",
            " - 0s - loss: 0.0378 - val_loss: 0.0815\n",
            "Epoch 672/1000\n",
            " - 0s - loss: 0.0404 - val_loss: 0.0817\n",
            "Epoch 673/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0820\n",
            "Epoch 674/1000\n",
            " - 0s - loss: 0.0423 - val_loss: 0.0819\n",
            "Epoch 675/1000\n",
            " - 0s - loss: 0.0311 - val_loss: 0.0820\n",
            "Epoch 676/1000\n",
            " - 0s - loss: 0.0453 - val_loss: 0.0822\n",
            "Epoch 677/1000\n",
            " - 0s - loss: 0.0421 - val_loss: 0.0824\n",
            "Epoch 678/1000\n",
            " - 0s - loss: 0.0437 - val_loss: 0.0825\n",
            "Epoch 679/1000\n",
            " - 0s - loss: 0.0383 - val_loss: 0.0827\n",
            "Epoch 680/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0828\n",
            "Epoch 681/1000\n",
            " - 0s - loss: 0.0225 - val_loss: 0.0828\n",
            "Epoch 682/1000\n",
            " - 0s - loss: 0.0517 - val_loss: 0.0829\n",
            "Epoch 683/1000\n",
            " - 0s - loss: 0.0538 - val_loss: 0.0831\n",
            "Epoch 684/1000\n",
            " - 0s - loss: 0.0217 - val_loss: 0.0829\n",
            "Epoch 685/1000\n",
            " - 0s - loss: 0.0492 - val_loss: 0.0827\n",
            "Epoch 686/1000\n",
            " - 0s - loss: 0.0653 - val_loss: 0.0824\n",
            "Epoch 687/1000\n",
            " - 0s - loss: 0.0569 - val_loss: 0.0819\n",
            "Epoch 688/1000\n",
            " - 0s - loss: 0.0296 - val_loss: 0.0813\n",
            "Epoch 689/1000\n",
            " - 0s - loss: 0.0254 - val_loss: 0.0808\n",
            "Epoch 690/1000\n",
            " - 0s - loss: 0.0398 - val_loss: 0.0803\n",
            "Epoch 691/1000\n",
            " - 0s - loss: 0.0401 - val_loss: 0.0799\n",
            "Epoch 692/1000\n",
            " - 0s - loss: 0.0538 - val_loss: 0.0794\n",
            "Epoch 693/1000\n",
            " - 0s - loss: 0.0295 - val_loss: 0.0789\n",
            "Epoch 694/1000\n",
            " - 0s - loss: 0.0507 - val_loss: 0.0785\n",
            "Epoch 695/1000\n",
            " - 0s - loss: 0.0631 - val_loss: 0.0780\n",
            "Epoch 696/1000\n",
            " - 0s - loss: 0.0309 - val_loss: 0.0777\n",
            "Epoch 697/1000\n",
            " - 0s - loss: 0.0388 - val_loss: 0.0775\n",
            "Epoch 698/1000\n",
            " - 0s - loss: 0.0526 - val_loss: 0.0774\n",
            "Epoch 699/1000\n",
            " - 0s - loss: 0.0278 - val_loss: 0.0774\n",
            "Epoch 700/1000\n",
            " - 0s - loss: 0.0544 - val_loss: 0.0776\n",
            "Epoch 701/1000\n",
            " - 0s - loss: 0.0317 - val_loss: 0.0777\n",
            "Epoch 702/1000\n",
            " - 0s - loss: 0.0570 - val_loss: 0.0781\n",
            "Epoch 703/1000\n",
            " - 0s - loss: 0.0490 - val_loss: 0.0784\n",
            "Epoch 704/1000\n",
            " - 0s - loss: 0.0466 - val_loss: 0.0787\n",
            "Epoch 705/1000\n",
            " - 0s - loss: 0.0413 - val_loss: 0.0791\n",
            "Epoch 706/1000\n",
            " - 0s - loss: 0.0326 - val_loss: 0.0796\n",
            "Epoch 707/1000\n",
            " - 0s - loss: 0.0410 - val_loss: 0.0801\n",
            "Epoch 708/1000\n",
            " - 0s - loss: 0.0231 - val_loss: 0.0807\n",
            "Epoch 709/1000\n",
            " - 0s - loss: 0.0330 - val_loss: 0.0814\n",
            "Epoch 710/1000\n",
            " - 0s - loss: 0.0438 - val_loss: 0.0819\n",
            "Epoch 711/1000\n",
            " - 0s - loss: 0.0497 - val_loss: 0.0823\n",
            "Epoch 712/1000\n",
            " - 0s - loss: 0.0320 - val_loss: 0.0826\n",
            "Epoch 713/1000\n",
            " - 0s - loss: 0.0346 - val_loss: 0.0830\n",
            "Epoch 714/1000\n",
            " - 0s - loss: 0.0381 - val_loss: 0.0831\n",
            "Epoch 715/1000\n",
            " - 0s - loss: 0.0374 - val_loss: 0.0830\n",
            "Epoch 716/1000\n",
            " - 0s - loss: 0.0313 - val_loss: 0.0830\n",
            "Epoch 717/1000\n",
            " - 0s - loss: 0.0275 - val_loss: 0.0828\n",
            "Epoch 718/1000\n",
            " - 0s - loss: 0.0729 - val_loss: 0.0828\n",
            "Epoch 719/1000\n",
            " - 0s - loss: 0.0291 - val_loss: 0.0827\n",
            "Epoch 720/1000\n",
            " - 0s - loss: 0.0735 - val_loss: 0.0826\n",
            "Epoch 721/1000\n",
            " - 0s - loss: 0.0355 - val_loss: 0.0825\n",
            "Epoch 722/1000\n",
            " - 0s - loss: 0.0390 - val_loss: 0.0823\n",
            "Epoch 723/1000\n",
            " - 0s - loss: 0.0316 - val_loss: 0.0821\n",
            "Epoch 724/1000\n",
            " - 0s - loss: 0.0348 - val_loss: 0.0818\n",
            "Epoch 725/1000\n",
            " - 0s - loss: 0.0227 - val_loss: 0.0814\n",
            "Epoch 726/1000\n",
            " - 0s - loss: 0.0247 - val_loss: 0.0811\n",
            "Epoch 727/1000\n",
            " - 0s - loss: 0.0486 - val_loss: 0.0806\n",
            "Epoch 728/1000\n",
            " - 0s - loss: 0.0459 - val_loss: 0.0801\n",
            "Epoch 729/1000\n",
            " - 0s - loss: 0.0496 - val_loss: 0.0798\n",
            "Epoch 730/1000\n",
            " - 0s - loss: 0.0352 - val_loss: 0.0794\n",
            "Epoch 731/1000\n",
            " - 0s - loss: 0.0568 - val_loss: 0.0791\n",
            "Epoch 732/1000\n",
            " - 0s - loss: 0.0470 - val_loss: 0.0789\n",
            "Epoch 733/1000\n",
            " - 0s - loss: 0.0275 - val_loss: 0.0787\n",
            "Epoch 734/1000\n",
            " - 0s - loss: 0.0317 - val_loss: 0.0783\n",
            "Epoch 735/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0779\n",
            "Epoch 736/1000\n",
            " - 0s - loss: 0.0603 - val_loss: 0.0776\n",
            "Epoch 737/1000\n",
            " - 0s - loss: 0.0290 - val_loss: 0.0773\n",
            "Epoch 738/1000\n",
            " - 0s - loss: 0.0343 - val_loss: 0.0773\n",
            "Epoch 739/1000\n",
            " - 0s - loss: 0.0321 - val_loss: 0.0774\n",
            "Epoch 740/1000\n",
            " - 0s - loss: 0.0289 - val_loss: 0.0775\n",
            "Epoch 741/1000\n",
            " - 0s - loss: 0.0405 - val_loss: 0.0776\n",
            "Epoch 742/1000\n",
            " - 0s - loss: 0.0573 - val_loss: 0.0777\n",
            "Epoch 743/1000\n",
            " - 0s - loss: 0.0316 - val_loss: 0.0779\n",
            "Epoch 744/1000\n",
            " - 0s - loss: 0.0668 - val_loss: 0.0782\n",
            "Epoch 745/1000\n",
            " - 0s - loss: 0.0235 - val_loss: 0.0785\n",
            "Epoch 746/1000\n",
            " - 0s - loss: 0.0564 - val_loss: 0.0788\n",
            "Epoch 747/1000\n",
            " - 0s - loss: 0.0591 - val_loss: 0.0793\n",
            "Epoch 748/1000\n",
            " - 0s - loss: 0.0438 - val_loss: 0.0799\n",
            "Epoch 749/1000\n",
            " - 0s - loss: 0.0583 - val_loss: 0.0808\n",
            "Epoch 750/1000\n",
            " - 0s - loss: 0.0442 - val_loss: 0.0815\n",
            "Epoch 751/1000\n",
            " - 0s - loss: 0.0594 - val_loss: 0.0824\n",
            "Epoch 752/1000\n",
            " - 0s - loss: 0.0252 - val_loss: 0.0833\n",
            "Epoch 753/1000\n",
            " - 0s - loss: 0.0289 - val_loss: 0.0840\n",
            "Epoch 754/1000\n",
            " - 0s - loss: 0.0432 - val_loss: 0.0846\n",
            "Epoch 755/1000\n",
            " - 0s - loss: 0.0568 - val_loss: 0.0853\n",
            "Epoch 756/1000\n",
            " - 0s - loss: 0.0496 - val_loss: 0.0860\n",
            "Epoch 757/1000\n",
            " - 0s - loss: 0.0390 - val_loss: 0.0867\n",
            "Epoch 758/1000\n",
            " - 0s - loss: 0.0390 - val_loss: 0.0873\n",
            "Epoch 759/1000\n",
            " - 0s - loss: 0.0604 - val_loss: 0.0875\n",
            "Epoch 760/1000\n",
            " - 0s - loss: 0.0250 - val_loss: 0.0876\n",
            "Epoch 761/1000\n",
            " - 0s - loss: 0.0298 - val_loss: 0.0875\n",
            "Epoch 762/1000\n",
            " - 0s - loss: 0.0266 - val_loss: 0.0875\n",
            "Epoch 763/1000\n",
            " - 0s - loss: 0.0291 - val_loss: 0.0874\n",
            "Epoch 764/1000\n",
            " - 0s - loss: 0.0429 - val_loss: 0.0873\n",
            "Epoch 765/1000\n",
            " - 0s - loss: 0.0247 - val_loss: 0.0872\n",
            "Epoch 766/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0869\n",
            "Epoch 767/1000\n",
            " - 0s - loss: 0.0452 - val_loss: 0.0867\n",
            "Epoch 768/1000\n",
            " - 0s - loss: 0.0348 - val_loss: 0.0866\n",
            "Epoch 769/1000\n",
            " - 0s - loss: 0.0229 - val_loss: 0.0865\n",
            "Epoch 770/1000\n",
            " - 0s - loss: 0.0275 - val_loss: 0.0863\n",
            "Epoch 771/1000\n",
            " - 0s - loss: 0.0284 - val_loss: 0.0861\n",
            "Epoch 772/1000\n",
            " - 0s - loss: 0.0334 - val_loss: 0.0860\n",
            "Epoch 773/1000\n",
            " - 0s - loss: 0.0512 - val_loss: 0.0856\n",
            "Epoch 774/1000\n",
            " - 0s - loss: 0.0316 - val_loss: 0.0853\n",
            "Epoch 775/1000\n",
            " - 0s - loss: 0.0291 - val_loss: 0.0848\n",
            "Epoch 776/1000\n",
            " - 0s - loss: 0.0351 - val_loss: 0.0843\n",
            "Epoch 777/1000\n",
            " - 0s - loss: 0.0296 - val_loss: 0.0838\n",
            "Epoch 778/1000\n",
            " - 0s - loss: 0.0322 - val_loss: 0.0834\n",
            "Epoch 779/1000\n",
            " - 0s - loss: 0.0269 - val_loss: 0.0831\n",
            "Epoch 780/1000\n",
            " - 0s - loss: 0.0474 - val_loss: 0.0828\n",
            "Epoch 781/1000\n",
            " - 0s - loss: 0.0300 - val_loss: 0.0826\n",
            "Epoch 782/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0825\n",
            "Epoch 783/1000\n",
            " - 0s - loss: 0.0413 - val_loss: 0.0824\n",
            "Epoch 784/1000\n",
            " - 0s - loss: 0.0437 - val_loss: 0.0823\n",
            "Epoch 785/1000\n",
            " - 0s - loss: 0.0334 - val_loss: 0.0822\n",
            "Epoch 786/1000\n",
            " - 0s - loss: 0.0474 - val_loss: 0.0821\n",
            "Epoch 787/1000\n",
            " - 0s - loss: 0.0195 - val_loss: 0.0820\n",
            "Epoch 788/1000\n",
            " - 0s - loss: 0.0369 - val_loss: 0.0819\n",
            "Epoch 789/1000\n",
            " - 0s - loss: 0.0392 - val_loss: 0.0817\n",
            "Epoch 790/1000\n",
            " - 0s - loss: 0.0616 - val_loss: 0.0816\n",
            "Epoch 791/1000\n",
            " - 0s - loss: 0.0469 - val_loss: 0.0816\n",
            "Epoch 792/1000\n",
            " - 0s - loss: 0.0410 - val_loss: 0.0815\n",
            "Epoch 793/1000\n",
            " - 0s - loss: 0.0347 - val_loss: 0.0815\n",
            "Epoch 794/1000\n",
            " - 0s - loss: 0.0451 - val_loss: 0.0815\n",
            "Epoch 795/1000\n",
            " - 0s - loss: 0.0499 - val_loss: 0.0815\n",
            "Epoch 796/1000\n",
            " - 0s - loss: 0.0322 - val_loss: 0.0815\n",
            "Epoch 797/1000\n",
            " - 0s - loss: 0.0496 - val_loss: 0.0813\n",
            "Epoch 798/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0812\n",
            "Epoch 799/1000\n",
            " - 0s - loss: 0.0490 - val_loss: 0.0812\n",
            "Epoch 800/1000\n",
            " - 0s - loss: 0.0374 - val_loss: 0.0810\n",
            "Epoch 801/1000\n",
            " - 0s - loss: 0.0393 - val_loss: 0.0810\n",
            "Epoch 802/1000\n",
            " - 0s - loss: 0.0252 - val_loss: 0.0808\n",
            "Epoch 803/1000\n",
            " - 0s - loss: 0.0350 - val_loss: 0.0806\n",
            "Epoch 804/1000\n",
            " - 0s - loss: 0.0354 - val_loss: 0.0806\n",
            "Epoch 805/1000\n",
            " - 0s - loss: 0.0427 - val_loss: 0.0808\n",
            "Epoch 806/1000\n",
            " - 0s - loss: 0.0287 - val_loss: 0.0810\n",
            "Epoch 807/1000\n",
            " - 0s - loss: 0.0273 - val_loss: 0.0813\n",
            "Epoch 808/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0816\n",
            "Epoch 809/1000\n",
            " - 0s - loss: 0.0320 - val_loss: 0.0818\n",
            "Epoch 810/1000\n",
            " - 0s - loss: 0.0440 - val_loss: 0.0822\n",
            "Epoch 811/1000\n",
            " - 0s - loss: 0.0277 - val_loss: 0.0825\n",
            "Epoch 812/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0828\n",
            "Epoch 813/1000\n",
            " - 0s - loss: 0.0274 - val_loss: 0.0830\n",
            "Epoch 814/1000\n",
            " - 0s - loss: 0.0334 - val_loss: 0.0833\n",
            "Epoch 815/1000\n",
            " - 0s - loss: 0.0317 - val_loss: 0.0836\n",
            "Epoch 816/1000\n",
            " - 0s - loss: 0.0345 - val_loss: 0.0838\n",
            "Epoch 817/1000\n",
            " - 0s - loss: 0.0482 - val_loss: 0.0838\n",
            "Epoch 818/1000\n",
            " - 0s - loss: 0.0296 - val_loss: 0.0840\n",
            "Epoch 819/1000\n",
            " - 0s - loss: 0.0207 - val_loss: 0.0842\n",
            "Epoch 820/1000\n",
            " - 0s - loss: 0.0387 - val_loss: 0.0842\n",
            "Epoch 821/1000\n",
            " - 0s - loss: 0.0219 - val_loss: 0.0841\n",
            "Epoch 822/1000\n",
            " - 0s - loss: 0.0343 - val_loss: 0.0839\n",
            "Epoch 823/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0839\n",
            "Epoch 824/1000\n",
            " - 0s - loss: 0.0233 - val_loss: 0.0840\n",
            "Epoch 825/1000\n",
            " - 0s - loss: 0.0351 - val_loss: 0.0843\n",
            "Epoch 826/1000\n",
            " - 0s - loss: 0.0273 - val_loss: 0.0848\n",
            "Epoch 827/1000\n",
            " - 0s - loss: 0.0294 - val_loss: 0.0853\n",
            "Epoch 828/1000\n",
            " - 0s - loss: 0.0340 - val_loss: 0.0858\n",
            "Epoch 829/1000\n",
            " - 0s - loss: 0.0626 - val_loss: 0.0862\n",
            "Epoch 830/1000\n",
            " - 0s - loss: 0.0255 - val_loss: 0.0866\n",
            "Epoch 831/1000\n",
            " - 0s - loss: 0.0456 - val_loss: 0.0868\n",
            "Epoch 832/1000\n",
            " - 0s - loss: 0.0407 - val_loss: 0.0869\n",
            "Epoch 833/1000\n",
            " - 0s - loss: 0.0332 - val_loss: 0.0869\n",
            "Epoch 834/1000\n",
            " - 0s - loss: 0.0594 - val_loss: 0.0869\n",
            "Epoch 835/1000\n",
            " - 0s - loss: 0.0347 - val_loss: 0.0868\n",
            "Epoch 836/1000\n",
            " - 0s - loss: 0.0316 - val_loss: 0.0868\n",
            "Epoch 837/1000\n",
            " - 0s - loss: 0.0461 - val_loss: 0.0866\n",
            "Epoch 838/1000\n",
            " - 0s - loss: 0.0265 - val_loss: 0.0864\n",
            "Epoch 839/1000\n",
            " - 0s - loss: 0.0554 - val_loss: 0.0861\n",
            "Epoch 840/1000\n",
            " - 0s - loss: 0.0294 - val_loss: 0.0861\n",
            "Epoch 841/1000\n",
            " - 0s - loss: 0.0472 - val_loss: 0.0860\n",
            "Epoch 842/1000\n",
            " - 0s - loss: 0.0297 - val_loss: 0.0860\n",
            "Epoch 843/1000\n",
            " - 0s - loss: 0.0396 - val_loss: 0.0859\n",
            "Epoch 844/1000\n",
            " - 0s - loss: 0.0339 - val_loss: 0.0858\n",
            "Epoch 845/1000\n",
            " - 0s - loss: 0.0558 - val_loss: 0.0856\n",
            "Epoch 846/1000\n",
            " - 0s - loss: 0.0296 - val_loss: 0.0853\n",
            "Epoch 847/1000\n",
            " - 0s - loss: 0.0476 - val_loss: 0.0851\n",
            "Epoch 848/1000\n",
            " - 0s - loss: 0.0359 - val_loss: 0.0850\n",
            "Epoch 849/1000\n",
            " - 0s - loss: 0.0376 - val_loss: 0.0849\n",
            "Epoch 850/1000\n",
            " - 0s - loss: 0.0294 - val_loss: 0.0847\n",
            "Epoch 851/1000\n",
            " - 0s - loss: 0.0393 - val_loss: 0.0847\n",
            "Epoch 852/1000\n",
            " - 0s - loss: 0.0242 - val_loss: 0.0847\n",
            "Epoch 853/1000\n",
            " - 0s - loss: 0.0266 - val_loss: 0.0847\n",
            "Epoch 854/1000\n",
            " - 0s - loss: 0.0667 - val_loss: 0.0847\n",
            "Epoch 855/1000\n",
            " - 0s - loss: 0.0283 - val_loss: 0.0846\n",
            "Epoch 856/1000\n",
            " - 0s - loss: 0.0272 - val_loss: 0.0847\n",
            "Epoch 857/1000\n",
            " - 0s - loss: 0.0460 - val_loss: 0.0848\n",
            "Epoch 858/1000\n",
            " - 0s - loss: 0.0162 - val_loss: 0.0850\n",
            "Epoch 859/1000\n",
            " - 0s - loss: 0.0262 - val_loss: 0.0851\n",
            "Epoch 860/1000\n",
            " - 0s - loss: 0.0484 - val_loss: 0.0853\n",
            "Epoch 861/1000\n",
            " - 0s - loss: 0.0398 - val_loss: 0.0855\n",
            "Epoch 862/1000\n",
            " - 0s - loss: 0.0385 - val_loss: 0.0856\n",
            "Epoch 863/1000\n",
            " - 0s - loss: 0.0211 - val_loss: 0.0859\n",
            "Epoch 864/1000\n",
            " - 0s - loss: 0.0251 - val_loss: 0.0861\n",
            "Epoch 865/1000\n",
            " - 0s - loss: 0.0196 - val_loss: 0.0863\n",
            "Epoch 866/1000\n",
            " - 0s - loss: 0.0279 - val_loss: 0.0866\n",
            "Epoch 867/1000\n",
            " - 0s - loss: 0.0410 - val_loss: 0.0869\n",
            "Epoch 868/1000\n",
            " - 0s - loss: 0.0486 - val_loss: 0.0870\n",
            "Epoch 869/1000\n",
            " - 0s - loss: 0.0499 - val_loss: 0.0870\n",
            "Epoch 870/1000\n",
            " - 0s - loss: 0.0363 - val_loss: 0.0869\n",
            "Epoch 871/1000\n",
            " - 0s - loss: 0.0401 - val_loss: 0.0869\n",
            "Epoch 872/1000\n",
            " - 0s - loss: 0.0318 - val_loss: 0.0868\n",
            "Epoch 873/1000\n",
            " - 0s - loss: 0.0481 - val_loss: 0.0867\n",
            "Epoch 874/1000\n",
            " - 0s - loss: 0.0325 - val_loss: 0.0865\n",
            "Epoch 875/1000\n",
            " - 0s - loss: 0.0249 - val_loss: 0.0864\n",
            "Epoch 876/1000\n",
            " - 0s - loss: 0.0494 - val_loss: 0.0861\n",
            "Epoch 877/1000\n",
            " - 0s - loss: 0.0356 - val_loss: 0.0858\n",
            "Epoch 878/1000\n",
            " - 0s - loss: 0.0407 - val_loss: 0.0855\n",
            "Epoch 879/1000\n",
            " - 0s - loss: 0.0247 - val_loss: 0.0853\n",
            "Epoch 880/1000\n",
            " - 0s - loss: 0.0563 - val_loss: 0.0849\n",
            "Epoch 881/1000\n",
            " - 0s - loss: 0.0242 - val_loss: 0.0846\n",
            "Epoch 882/1000\n",
            " - 0s - loss: 0.0579 - val_loss: 0.0843\n",
            "Epoch 883/1000\n",
            " - 0s - loss: 0.0446 - val_loss: 0.0839\n",
            "Epoch 884/1000\n",
            " - 0s - loss: 0.0364 - val_loss: 0.0836\n",
            "Epoch 885/1000\n",
            " - 0s - loss: 0.0455 - val_loss: 0.0834\n",
            "Epoch 886/1000\n",
            " - 0s - loss: 0.0481 - val_loss: 0.0832\n",
            "Epoch 887/1000\n",
            " - 0s - loss: 0.0289 - val_loss: 0.0831\n",
            "Epoch 888/1000\n",
            " - 0s - loss: 0.0456 - val_loss: 0.0830\n",
            "Epoch 889/1000\n",
            " - 0s - loss: 0.0305 - val_loss: 0.0830\n",
            "Epoch 890/1000\n",
            " - 0s - loss: 0.0493 - val_loss: 0.0833\n",
            "Epoch 891/1000\n",
            " - 0s - loss: 0.0465 - val_loss: 0.0837\n",
            "Epoch 892/1000\n",
            " - 0s - loss: 0.0348 - val_loss: 0.0841\n",
            "Epoch 893/1000\n",
            " - 0s - loss: 0.0176 - val_loss: 0.0846\n",
            "Epoch 894/1000\n",
            " - 0s - loss: 0.0249 - val_loss: 0.0851\n",
            "Epoch 895/1000\n",
            " - 0s - loss: 0.0436 - val_loss: 0.0857\n",
            "Epoch 896/1000\n",
            " - 0s - loss: 0.0307 - val_loss: 0.0861\n",
            "Epoch 897/1000\n",
            " - 0s - loss: 0.0359 - val_loss: 0.0866\n",
            "Epoch 898/1000\n",
            " - 0s - loss: 0.0489 - val_loss: 0.0869\n",
            "Epoch 899/1000\n",
            " - 0s - loss: 0.0437 - val_loss: 0.0872\n",
            "Epoch 900/1000\n",
            " - 0s - loss: 0.0415 - val_loss: 0.0874\n",
            "Epoch 901/1000\n",
            " - 0s - loss: 0.0345 - val_loss: 0.0877\n",
            "Epoch 902/1000\n",
            " - 0s - loss: 0.0266 - val_loss: 0.0879\n",
            "Epoch 903/1000\n",
            " - 0s - loss: 0.0404 - val_loss: 0.0880\n",
            "Epoch 904/1000\n",
            " - 0s - loss: 0.0423 - val_loss: 0.0882\n",
            "Epoch 905/1000\n",
            " - 0s - loss: 0.0523 - val_loss: 0.0884\n",
            "Epoch 906/1000\n",
            " - 0s - loss: 0.0319 - val_loss: 0.0886\n",
            "Epoch 907/1000\n",
            " - 0s - loss: 0.0309 - val_loss: 0.0888\n",
            "Epoch 908/1000\n",
            " - 0s - loss: 0.0344 - val_loss: 0.0889\n",
            "Epoch 909/1000\n",
            " - 0s - loss: 0.0307 - val_loss: 0.0890\n",
            "Epoch 910/1000\n",
            " - 0s - loss: 0.0470 - val_loss: 0.0887\n",
            "Epoch 911/1000\n",
            " - 0s - loss: 0.0556 - val_loss: 0.0884\n",
            "Epoch 912/1000\n",
            " - 0s - loss: 0.0313 - val_loss: 0.0881\n",
            "Epoch 913/1000\n",
            " - 0s - loss: 0.0478 - val_loss: 0.0878\n",
            "Epoch 914/1000\n",
            " - 0s - loss: 0.0305 - val_loss: 0.0876\n",
            "Epoch 915/1000\n",
            " - 0s - loss: 0.0454 - val_loss: 0.0872\n",
            "Epoch 916/1000\n",
            " - 0s - loss: 0.0670 - val_loss: 0.0869\n",
            "Epoch 917/1000\n",
            " - 0s - loss: 0.0195 - val_loss: 0.0867\n",
            "Epoch 918/1000\n",
            " - 0s - loss: 0.0343 - val_loss: 0.0863\n",
            "Epoch 919/1000\n",
            " - 0s - loss: 0.0315 - val_loss: 0.0859\n",
            "Epoch 920/1000\n",
            " - 0s - loss: 0.0436 - val_loss: 0.0853\n",
            "Epoch 921/1000\n",
            " - 0s - loss: 0.0227 - val_loss: 0.0849\n",
            "Epoch 922/1000\n",
            " - 0s - loss: 0.0337 - val_loss: 0.0846\n",
            "Epoch 923/1000\n",
            " - 0s - loss: 0.0344 - val_loss: 0.0845\n",
            "Epoch 924/1000\n",
            " - 0s - loss: 0.0361 - val_loss: 0.0846\n",
            "Epoch 925/1000\n",
            " - 0s - loss: 0.0282 - val_loss: 0.0848\n",
            "Epoch 926/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0849\n",
            "Epoch 927/1000\n",
            " - 0s - loss: 0.0282 - val_loss: 0.0851\n",
            "Epoch 928/1000\n",
            " - 0s - loss: 0.0411 - val_loss: 0.0853\n",
            "Epoch 929/1000\n",
            " - 0s - loss: 0.0456 - val_loss: 0.0853\n",
            "Epoch 930/1000\n",
            " - 0s - loss: 0.0242 - val_loss: 0.0853\n",
            "Epoch 931/1000\n",
            " - 0s - loss: 0.0431 - val_loss: 0.0852\n",
            "Epoch 932/1000\n",
            " - 0s - loss: 0.0330 - val_loss: 0.0851\n",
            "Epoch 933/1000\n",
            " - 0s - loss: 0.0348 - val_loss: 0.0849\n",
            "Epoch 934/1000\n",
            " - 0s - loss: 0.0386 - val_loss: 0.0848\n",
            "Epoch 935/1000\n",
            " - 0s - loss: 0.0498 - val_loss: 0.0845\n",
            "Epoch 936/1000\n",
            " - 0s - loss: 0.0358 - val_loss: 0.0841\n",
            "Epoch 937/1000\n",
            " - 0s - loss: 0.0675 - val_loss: 0.0837\n",
            "Epoch 938/1000\n",
            " - 0s - loss: 0.0306 - val_loss: 0.0835\n",
            "Epoch 939/1000\n",
            " - 0s - loss: 0.0236 - val_loss: 0.0833\n",
            "Epoch 940/1000\n",
            " - 0s - loss: 0.0274 - val_loss: 0.0833\n",
            "Epoch 941/1000\n",
            " - 0s - loss: 0.0353 - val_loss: 0.0831\n",
            "Epoch 942/1000\n",
            " - 0s - loss: 0.0368 - val_loss: 0.0830\n",
            "Epoch 943/1000\n",
            " - 0s - loss: 0.0308 - val_loss: 0.0831\n",
            "Epoch 944/1000\n",
            " - 0s - loss: 0.0411 - val_loss: 0.0831\n",
            "Epoch 945/1000\n",
            " - 0s - loss: 0.0518 - val_loss: 0.0832\n",
            "Epoch 946/1000\n",
            " - 0s - loss: 0.0249 - val_loss: 0.0833\n",
            "Epoch 947/1000\n",
            " - 0s - loss: 0.0232 - val_loss: 0.0833\n",
            "Epoch 948/1000\n",
            " - 0s - loss: 0.0276 - val_loss: 0.0833\n",
            "Epoch 949/1000\n",
            " - 0s - loss: 0.0323 - val_loss: 0.0834\n",
            "Epoch 950/1000\n",
            " - 0s - loss: 0.0282 - val_loss: 0.0836\n",
            "Epoch 951/1000\n",
            " - 0s - loss: 0.0407 - val_loss: 0.0838\n",
            "Epoch 952/1000\n",
            " - 0s - loss: 0.0293 - val_loss: 0.0840\n",
            "Epoch 953/1000\n",
            " - 0s - loss: 0.0256 - val_loss: 0.0843\n",
            "Epoch 954/1000\n",
            " - 0s - loss: 0.0501 - val_loss: 0.0846\n",
            "Epoch 955/1000\n",
            " - 0s - loss: 0.0399 - val_loss: 0.0848\n",
            "Epoch 956/1000\n",
            " - 0s - loss: 0.0340 - val_loss: 0.0851\n",
            "Epoch 957/1000\n",
            " - 0s - loss: 0.0436 - val_loss: 0.0853\n",
            "Epoch 958/1000\n",
            " - 0s - loss: 0.0304 - val_loss: 0.0856\n",
            "Epoch 959/1000\n",
            " - 0s - loss: 0.0367 - val_loss: 0.0858\n",
            "Epoch 960/1000\n",
            " - 0s - loss: 0.0351 - val_loss: 0.0862\n",
            "Epoch 961/1000\n",
            " - 0s - loss: 0.0225 - val_loss: 0.0865\n",
            "Epoch 962/1000\n",
            " - 0s - loss: 0.0319 - val_loss: 0.0866\n",
            "Epoch 963/1000\n",
            " - 0s - loss: 0.0311 - val_loss: 0.0866\n",
            "Epoch 964/1000\n",
            " - 0s - loss: 0.0155 - val_loss: 0.0866\n",
            "Epoch 965/1000\n",
            " - 0s - loss: 0.0432 - val_loss: 0.0865\n",
            "Epoch 966/1000\n",
            " - 0s - loss: 0.0425 - val_loss: 0.0863\n",
            "Epoch 967/1000\n",
            " - 0s - loss: 0.0427 - val_loss: 0.0861\n",
            "Epoch 968/1000\n",
            " - 0s - loss: 0.0237 - val_loss: 0.0859\n",
            "Epoch 969/1000\n",
            " - 0s - loss: 0.0313 - val_loss: 0.0857\n",
            "Epoch 970/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0855\n",
            "Epoch 971/1000\n",
            " - 0s - loss: 0.0432 - val_loss: 0.0854\n",
            "Epoch 972/1000\n",
            " - 0s - loss: 0.0253 - val_loss: 0.0855\n",
            "Epoch 973/1000\n",
            " - 0s - loss: 0.0452 - val_loss: 0.0855\n",
            "Epoch 974/1000\n",
            " - 0s - loss: 0.0540 - val_loss: 0.0854\n",
            "Epoch 975/1000\n",
            " - 0s - loss: 0.0423 - val_loss: 0.0855\n",
            "Epoch 976/1000\n",
            " - 0s - loss: 0.0267 - val_loss: 0.0857\n",
            "Epoch 977/1000\n",
            " - 0s - loss: 0.0384 - val_loss: 0.0859\n",
            "Epoch 978/1000\n",
            " - 0s - loss: 0.0337 - val_loss: 0.0861\n",
            "Epoch 979/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0861\n",
            "Epoch 980/1000\n",
            " - 0s - loss: 0.0469 - val_loss: 0.0860\n",
            "Epoch 981/1000\n",
            " - 0s - loss: 0.0475 - val_loss: 0.0856\n",
            "Epoch 982/1000\n",
            " - 0s - loss: 0.0485 - val_loss: 0.0852\n",
            "Epoch 983/1000\n",
            " - 0s - loss: 0.0279 - val_loss: 0.0849\n",
            "Epoch 984/1000\n",
            " - 0s - loss: 0.0271 - val_loss: 0.0846\n",
            "Epoch 985/1000\n",
            " - 0s - loss: 0.0404 - val_loss: 0.0844\n",
            "Epoch 986/1000\n",
            " - 0s - loss: 0.0255 - val_loss: 0.0841\n",
            "Epoch 987/1000\n",
            " - 0s - loss: 0.0277 - val_loss: 0.0838\n",
            "Epoch 988/1000\n",
            " - 0s - loss: 0.0587 - val_loss: 0.0836\n",
            "Epoch 989/1000\n",
            " - 0s - loss: 0.0282 - val_loss: 0.0835\n",
            "Epoch 990/1000\n",
            " - 0s - loss: 0.0445 - val_loss: 0.0834\n",
            "Epoch 991/1000\n",
            " - 0s - loss: 0.0392 - val_loss: 0.0834\n",
            "Epoch 992/1000\n",
            " - 0s - loss: 0.0298 - val_loss: 0.0833\n",
            "Epoch 993/1000\n",
            " - 0s - loss: 0.0335 - val_loss: 0.0833\n",
            "Epoch 994/1000\n",
            " - 0s - loss: 0.0443 - val_loss: 0.0833\n",
            "Epoch 995/1000\n",
            " - 0s - loss: 0.0379 - val_loss: 0.0833\n",
            "Epoch 996/1000\n",
            " - 0s - loss: 0.0296 - val_loss: 0.0834\n",
            "Epoch 997/1000\n",
            " - 0s - loss: 0.0549 - val_loss: 0.0837\n",
            "Epoch 998/1000\n",
            " - 0s - loss: 0.0349 - val_loss: 0.0839\n",
            "Epoch 999/1000\n",
            " - 0s - loss: 0.0399 - val_loss: 0.0841\n",
            "Epoch 1000/1000\n",
            " - 0s - loss: 0.0380 - val_loss: 0.0842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYgkKkwRbvBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-_4vm6LQfHP",
        "colab_type": "text"
      },
      "source": [
        "## 训练过程可视化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v87JVxgaQfHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cac7a47c-3025-4531-843a-db9bf5b925ab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 绘制训练 & 验证的损失值\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3zU9f3A8df7LjskBEKYYYMsQcCw\nRAQUEdSfo07UuoutA1vbWmzd1op2WKtYtYpW6qjiKAqKiltkBET2noEASYCQQcbdfX5/fL93uUsu\nyQVyCcm9n4/HPbj7zs/3jnzf388WYwxKKaUil6OxE6CUUqpxaSBQSqkIp4FAKaUinAYCpZSKcBoI\nlFIqwmkgUEqpCKeBQKkQiEg3ETEiEhXCtteLyLfHexylGooGAtXsiMgOESkTkTaVlv9g34S7NU7K\nlDoxaSBQzdV2YIr3g4gMBBIaLzlKnbg0EKjmajZwrd/n64BX/TcQkZYi8qqI5IjIThG5V0Qc9jqn\niPxFRHJFZBtwXpB9XxKRbBHZIyJ/FBFnXRMpIh1FZK6IHBSRLSLyM791w0UkU0SOiMh+EfmbvTxO\nRP4jInkiclhElolIu7qeWykvDQSquVoMJItIP/sGfSXwn0rbPA20BHoAY7ECxw32up8B5wNDgAzg\n0kr7vgK4gF72NhOBm48hnW8CWUBH+xx/EpEz7XVPAU8ZY5KBnsBb9vLr7HR3BlKBnwNHj+HcSgEa\nCFTz5s0VnA2sB/Z4V/gFh3uMMQXGmB3AX4Gf2ptcDvzdGLPbGHMQeMxv33bAucAvjTFFxpgDwJP2\n8UImIp2B0cDvjDElxpiVwItU5GTKgV4i0sYYU2iMWey3PBXoZYxxG2OWG2OO1OXcSvnTQKCas9nA\nVcD1VCoWAtoA0cBOv2U7gU72+47A7krrvLra+2bbRTOHgeeBtnVMX0fgoDGmoJo03AScBGywi3/O\n97uuBcCbIrJXRJ4Qkeg6nlspHw0EqtkyxuzEqjQ+F3i30upcrCfrrn7LulCRa8jGKnrxX+e1GygF\n2hhjUuxXsjFmQB2TuBdoLSJJwdJgjNlsjJmCFWAeB+aISKIxptwY85Axpj9wGlYR1rUodYw0EKjm\n7ibgTGNMkf9CY4wbq8z9URFJEpGuwF1U1CO8BUwTkXQRaQVM99s3G/gE+KuIJIuIQ0R6isjYuiTM\nGLMbWAQ8ZlcAD7LT+x8AEblGRNKMMR7gsL2bR0TGi8hAu3jrCFZA89Tl3Er500CgmjVjzFZjTGY1\nq+8AioBtwLfA68Ase92/sIpffgRWUDVHcS0QA6wDDgFzgA7HkMQpQDes3MF7wAPGmM/sdZOAtSJS\niFVxfKUx5ijQ3j7fEay6j6+wiouUOiaiE9MopVRk0xyBUkpFOA0ESikV4TQQKKVUhNNAoJRSEa7J\nDYXbpk0b061bt8ZOhlJKNSnLly/PNcakBVvX5AJBt27dyMysrjWgUkqpYERkZ3Xrwlo0JCKTRGSj\nPari9Gq2uVxE1onIWhF5PZzpUUopVVXYcgR2r8eZWAN+ZQHLRGSuMWad3za9gXuA0caYQyJS17Fa\nlFJKHadw5giGA1uMMduMMWVYw+1eWGmbnwEzjTGHAOxRHJVSSjWgcNYRdCJw9MYsYESlbU4CEJHv\nACfwoDHm48oHEpGpwFSALl26VF5NeXk5WVlZlJSU1E/Km4C4uDjS09OJjtZBJ5VSx6exK4ujgN7A\nOCAd+FpEBhpjDvtvZIx5AXgBICMjo8qYGFlZWSQlJdGtWzdEJPypbmTGGPLy8sjKyqJ79+6NnRyl\nVBMXzqKhPQQO45uO38Qgtixgrj2s7nZgE1ZgqJOSkhJSU1MjIggAiAipqakRlQNSSoVPOAPBMqC3\niHQXkRis2ZvmVtrmfazcACLSBquoaNuxnCxSgoBXpF2vUip8whYIjDEu4HasoXzXA28ZY9aKyMMi\ncoG92QIgT0TWAV8AvzXG5IUrTWUuD0eOlofr8Eop1SSFtY7AGDMfmF9p2f1+7w3WZCB3hTMdXpv3\nF+A2hkHpKfV63Ly8PM466ywA9u3bh9PpJC3N6sC3dOlSYmJiaj3GDTfcwPTp0+nTp0+9pk0ppWrT\n2JXFDcodprkXUlNTWblyJQAPPvggLVq04De/+U3ANsYYjDE4HMEzYS+//HJY0qaUUrXRQefCaMuW\nLfTv35+rr76aAQMGkJ2dzdSpU8nIyGDAgAE8/PDDvm1PP/10Vq5cicvlIiUlhenTp3PKKacwatQo\nDhzQ7hVKqfBpdjmChz5Yy7q9R4KuKyp1AZAYW7fL7t8xmQf+r67zkls2bNjAq6++SkZGBgAzZsyg\ndevWuFwuxo8fz6WXXkr//v0D9snPz2fs2LHMmDGDu+66i1mzZjF9etAROpRS6rhpjiDMevbs6QsC\nAG+88QZDhw5l6NChrF+/nnXr1lXZJz4+nsmTJwNw6qmnsmPHjoZKrlIqAjW7HEFNT+6rsqx+agM7\ntWyw5peJiYm+95s3b+app55i6dKlpKSkcM011wTtC+Bfuex0OnG5XA2SVqVUZIqYHEFhSUWz0fBU\nGdfuyJEjJCUlkZycTHZ2NgsWLGiklCilVIVmlyOoztFyT8UHAzRCf6yhQ4fSv39/+vbtS9euXRk9\nenTDJ0IppSoRE6YmleGSkZFhKk9Ms379evr161fjfgeLysg6VAzAgI4tcTqafs/cUK5bKaUARGS5\nMSYj2LqIKRqKCrjxN63gp5RS4RQxgcA/B6BhQCmlKkRMIAjIEWgkUEopn4gJBDFRDqLs4R00Diil\nVIWICQQiQrvk2MZOhlJKnXAiJhAE0CyBUkr5RFQg8HYmru84kJeXx+DBgxk8eDDt27enU6dOvs9l\nZWUhH2fWrFns27evnlOnlFI1i5gOZRZvhXH9hoJQhqEOxaxZsxg6dCjt27ev1/QppVRNIioQhCcM\n1Ozf//43M2fOpKysjNNOO41nnnkGj8fDDTfcwMqVKzHGMHXqVNq1a8fKlSu54ooriI+PD3lCG6WU\nOl7NLxB8NB32rQ66qoXHQ49yD9ExzopyolC0HwiTZ9Q5KWvWrOG9995j0aJFREVFMXXqVN588016\n9uxJbm4uq1db6Tx8+DApKSk8/fTTPPPMMwwePLjO51JKqWPV/AJBDRp6UInPPvuMZcuW+YahPnr0\nKJ07d+acc85h48aNTJs2jfPOO4+JEyc2cMqUUqpC8wsENTy5FxaXsetgMSe1SyIu2hn2pBhjuPHG\nG3nkkUeqrFu1ahUfffQRM2fO5J133uGFF14Ie3qUUiqYyGo1ZP/bUOPsTZgwgbfeeovc3FzAal20\na9cucnJyMMZw2WWX8fDDD7NixQoAkpKSKCgoaJjEKaWUrfnlCGoiDVtdPHDgQB544AEmTJiAx+Mh\nOjqa5557DqfTyU033YQxBhHh8ccfB+CGG27g5ptv1spipVSDiphhqAGOHC1nR14Rvdq2ICGm6cdA\nHYZaKRUqHYZaKaVUtSIqEPh6FjetTJBSSoVVWAOBiEwSkY0iskVEpgdZf72I5IjISvt187Geq6kV\ncR2vSLtepVT4hK2gXEScwEzgbCALWCYic40x6ypt+l9jzO3Hc664uDjy8vJITU1Faugo1hg9i8PB\nGENeXh5xcXGNnRSlVDMQzhrT4cAWY8w2ABF5E7gQqBwIjlt6ejpZWVnk5OTUuF1puZucwjI8B2OI\nbYB+BOEUFxdHenp6YydDKdUMhDMQdAJ2+33OAkYE2e4SETkD2AT8yhizu/IGIjIVmArQpUuXKgeI\njo6me/futSZo+c5D/Oz1Rbx8/TDG920b0kUopVRz19iVxR8A3Ywxg4BPgX8H28gY84IxJsMYk5GW\nlnbMJ+vSOgGAnXlFx3wMpZRqbsIZCPYAnf0+p9vLfIwxecaYUvvji8CpYUwPbVrEEB/tZPeho+E8\njVJKNSnhDATLgN4i0l1EYoArgbn+G4hIB7+PFwDrw5geRISEGCelLnc4T6OUUk1K2AKBMcYF3A4s\nwLrBv2WMWSsiD4vIBfZm00RkrYj8CEwDrg9XeryinMKirXl8uzk33KdSSqkmoVkMMVEXpz/+OVl2\n0dCOGefVV7KUUuqEpkNM+Il2RtwlK6VUjSLurhjtbOjpaZRS6sQWcYEgyhFxl6yUUjWKuLviuuwj\njZ0EpZQ6oURcIFBKKRVIA4FSSkU4DQRKKRXhNBAopVSE00CglFIRLqIDgdvTtHpVK6VUOERcIGjT\nItb3vtztacSUKKXUiSHiAsFHd47xvXdpjkAppSIvELROjPG9L3NpjkAppSIuEDgdwnPXDAVgy4HC\nRk6NUko1vogLBACndE4BYPOBgkZOiVJKNb6IDARxUU4AyrVoSCmlIjMQREdZl13u1spipZSKzEBg\nz0lQps1HlVIqQgOBPSeBS3MESikVmYHA4RCcDtEOZUopRYQGArCKhzQQKKVURAcCh9YRKKUUERwI\nYpwOzREopRQRHAiinQ7KXVpZrJRSkRsIorSOQCmlIMyBQEQmichGEdkiItNr2O4SETEikhHO9PjT\nOgKllLKELRCIiBOYCUwG+gNTRKR/kO2SgDuBJeFKSzBaR6CUUpZw5giGA1uMMduMMWXAm8CFQbZ7\nBHgcKAljWqqIiXJQUq6BQCmlwhkIOgG7/T5n2ct8RGQo0NkYM6+mA4nIVBHJFJHMnJyceklcQoyT\no2XuejmWUko1ZY1WWSwiDuBvwK9r29YY84IxJsMYk5GWllYv50+MiaKozFUvx1JKqaYsnIFgD9DZ\n73O6vcwrCTgZ+FJEdgAjgbkNVWGcGBtFUakGAqWUCmcgWAb0FpHuIhIDXAnM9a40xuQbY9oYY7oZ\nY7oBi4ELjDGZYUyTT2KskyItGlJKqfAFAmOMC7gdWACsB94yxqwVkYdF5IJwnTdUCTFRFGuOQCml\niArnwY0x84H5lZbdX82248KZlsoSY6wcgTEGEWnIUyul1AklYnsWx0Zb01VqpzKlVKSL2EAQ47Qu\nvUznLVZKRbjIDQRRGgiUUgo0EGjRkFIq4kVuINCiIaWUAiI5EGjRkFJKARoIKNVAoJSKcBEfCLSO\nQCkV6SI2EMRqHYFSSgERHAi0jkAppSwRGwji7J7F+4406Hw4Sil1wonYQNCnfRJdWifw3oo9tW+s\nlFLNWMQGgmingzG927B+35HGTopSSjWqiA0EYBUPudymsZOhlFKNKqIDQZRTtPmoUiriRXQgiHE6\ncGkgUEpFuIgOBFEOBx4Dbo8WDymlIldEB4LoKGtmsnLNFSilIlhkBwKHdfkaCJRSkSyyA4HTyhFo\nyyGlVCSL6EAQ5dQcgVJKRXQg8E5OU66VxUqpCBZSIBCRniISa78fJyLTRCQlvEkLvyi7aKhcB55T\nSkWwUHME7wBuEekFvAB0Bl4PW6oaSLSdI3B5NBAopSJXqIHAY4xxARcDTxtjfgt0CF+yGoa3srjM\npUVDSqnIFWogKBeRKcB1wIf2sujadhKRSSKyUUS2iMj0IOt/LiKrRWSliHwrIv1DT/rx0xyBUkqF\nHghuAEYBjxpjtotId2B2TTuIiBOYCUwG+gNTgtzoXzfGDDTGDAaeAP5Wp9QfJ201pJRSEBXKRsaY\ndcA0ABFpBSQZYx6vZbfhwBZjzDZ7vzeBC4F1fsf1HwM6EWjQMhpv0VC59iNQSkWwUFsNfSkiySLS\nGlgB/EtEant67wTs9vucZS+rfOzbRGQrVo5gWjXnnyoimSKSmZOTE0qSQ+ItGpr74956O6ZSSjU1\noRYNtbSf3n8CvGqMGQFMqI8EGGNmGmN6Ar8D7q1mmxeMMRnGmIy0tLT6OC1QEQheX7Kr3o6plFJN\nTaiBIEpEOgCXU1FZXJs9WM1MvdLtZdV5E7goxGPXiyiHNOTplFLqhBRqIHgYWABsNcYsE5EewOZa\n9lkG9BaR7iISA1wJzPXfQER6+308L4Rj1quYqIjuWK2UUkDolcVvA2/7fd4GXFLLPi4RuR0rgDiB\nWcaYtSLyMJBpjJkL3C4iE4By4BBW89QG458j2LS/gJPaJTXk6ZVS6oQQUiAQkXTgaWC0vegb4E5j\nTFZN+xlj5gPzKy273+/9nXVKbT3z1hEATHzya368fyItE2rtHqGUUs1KqGUjL2MV63S0Xx/Yy5o0\n/0AAUFBa3kgpUUqpxhNqIEgzxrxsjHHZr1eA+mu+00i8/Qi8CktdjZQSpZRqPKEGgjwRuUZEnPbr\nGiAvnAlrCFGVcgRHjmogUEpFnlADwY1YTUf3AdnApcD1YUpTg4mpXDRUokVDSqnIE1IgMMbsNMZc\nYIxJM8a0NcZcRC2thpqCKC0aUkqp45qh7K56S0Ujqdyh7O45qziiuQKlVIQ5nkDQ5LvligReQqnL\nw7NfbG2k1CilVOM4nkDQLIbsXPXgRL65e7zvs8c0i8tSSqmQ1dihTEQKCH7DFyA+LClqYMlx0ZSU\nu32fjQYCpVSEqTEQGGMiYsyFKEdFxkjjgFIq0uioa4DTr65A44BSKtJoIAD8MgSaI1BKRRwNBAQW\nDf2YdZgrX/ieUpe7hj2UUqr5CGn00ebOP0ewfOchADbvL+TkTi0bKUVKKdVwNEdAYI7AyyFNvpuE\nUkqFRAMBEGzGyiCxQSmlmiW93VG1hzGANP2O00opFRINBNXQee2VUpFCA4FSSkU4DQTVcGuHAqVU\nhNBAUI2jZdqPQCkVGTQQVOPiZxc1dhKUUqpBaCBQSqkIp4FAKaUinAYCpZSKcGENBCIySUQ2isgW\nEZkeZP1dIrJORFaJyEIR6RrO9CillKoqbIFARJzATGAy0B+YIiL9K232A5BhjBkEzAGeCFd6jsVr\nS3bi9mgzUqVU8xbOHMFwYIsxZpsxpgx4E7jQfwNjzBfGmGL742IgPYzpqbM/vLeG/y7b3djJUEqp\nsApnIOgE+N9Fs+xl1bkJ+CjYChGZKiKZIpKZk5NTj0ms3b4jJQ16PqWUamgnRGWxiFwDZAB/Drbe\nGPOCMSbDGJORlpbWoGkrLQ/sWPbZuv0UlJQ3aBqUUiqcwhkI9gCd/T6n28sCiMgE4A/ABcaY0jCm\np0ZPXDKI03qm8uzVQwOWH/ULBNtzi7j51UzunrOqoZOnlFJhE85AsAzoLSLdRSQGuBKY67+BiAwB\nnscKAgfCmJZaXT6sM6//bCRdWicELPcfaqKwxAXAroNWtcZL326n2/R5FJW6Gi6hSilVz8IWCIwx\nLuB2YAGwHnjLGLNWRB4WkQvszf4MtADeFpGVIjK3msM1GGel8adFwBiDMcY3EJ139rKXv9sOQF5h\nWcMmUiml6lFY5yw2xswH5ldadr/f+wnhPP+xqDxFpdMh3Pv+Gl5bsot3bz3N2sYOFjqbpVKqOTgh\nKotPJIbAfgMiwmtLdlnrfDmCmvdRSqmmRANBJZWnIXjdDgIAbo/1r9POCnins9SpC5RSTZkGgko8\nNdzVXR4rEjgqZQm8y5VSqinSQFBJTU/35e7AoiFvHUGZS7MESqmmSwNBHZTYfQocIhwuLmNnntWM\nVHMESqmmTANBJT3TWtA1NYEnLh1UZV2py7rhHy4u59dv/ehb7s0pHK9FW3PpNn0e2flH6+V4SikV\nCg0ElcTHOPnqt+O5PKNzlXU7cosAWJd9hIUbKvq/udzV5wg27S/gw1V7GfmnhXy+YX+N535tsVUx\nnbnj0LEkXSmljklY+xE0N3/7dFPQ5a4ahqqe+OTXvvcPfbCOM/u2q3ZbbzNUhwhLtuWxek8+N4/p\ncYypVUqp0GggqAflNeQIArZz1bydt6pBBK54YTGABgKlVNhp0VA9cIVYR1BeyyQ3FTmC406SUkqF\nTANBPQi11VBtOYeKOKGRQCnVcDQQ1INQWw3VlnPw9mHQHIFSqiFpIKgH9ZUj8I5lJDqanVKqAWkg\nqMFNp3cPabuQcwS11BEopVRj0EBQg5+P7RnSdv5FPrmFpdz11kryj1adztJda2WxRYuGlFINSQNB\nDWKcoX09/kVD9/9vDe+u2MMpD31S5/N5B7z784KNvmVGhzZVSoWZBoIatIgLrZuFf9HQwaKaZytb\nlXW42nXee/6GfQW+ZVqapJQKNw0ENag8bWV1XG4Pi7fl8em6/cRFO33L757zY5VtL3jmu2qPE2wI\n7NqKk5RS6nhpz+JaRDmk1kpel8dwpd0TeNKA9r7lb2Vm1Xr8NXvy6dw6gZbx0UHX1zQ/Ql2VlLsp\nLnPTOjGm3o6plGr6NEdQi3i/J/zqlPkNHfHx2n11Ov75T3/LtS8tAY4/R3CkpJxL/rmI7fbgeJXd\n8PIyhj7yaZ3Sp5Rq/jQQ1KJTq/hat6nrfAQe++buHbX0x6x8XG5P0Elx3HXIESxcv5/lOw/x98+C\nD473/ba8OqVTKRUZNBDUYtb1wzi5U3LAso1/nMTkkyuKgGZ+sTWkYw3tkgJAuR04Sv1yEst2HAoa\nCDx1yBE47I5ote2iLZGUUv40ENSiY0o8U4Z3CVgWG+XkoQsG1PlYbVrEAhX9DvyLlIwxvkHn/Lk9\nhtzCUv63cg+Fpa4aj+8LBCHUaSillJdWFocg2PDRobYo8hdr1ze43IbDxWUs9iuqMQR/kncbw5XP\nL2ZbbhEnd0rmwzvGAPD1phxOapdE+5ZxVdJUWwVzmctDdIh9JJRSzZ8GghB0bZNYZZnjGMYDio2y\nbr4L1u7j7ndWBazbc/goQTIEeDywza78XbPniG/5tbOW0i45liW/n+CXJuvf2iqYy1weEmPrnHyl\nVDMV1sdCEZkkIhtFZIuITA+y/gwRWSEiLhG5NJxpOR7j+7TltZtHBCw7lmad3kBQOQgA3D1nVdCi\nn8qVxQUl5b6in/1HSittHWKOoJbB77blFLL3sM6brFSkCFsgEBEnMBOYDPQHpohI/0qb7QKuB14P\nVzrqy8mdWgZ8bp0YwzUju1SzdXAxUTV/3euyj1RZNn9VdsDngQ9+Uu2N3FsJXFsVQGm5tX9RqYsD\nBSVV1p/51684bcbnNR9EKdVshDNHMBzYYozZZowpA94ELvTfwBizwxizCqhb+8tGEFWpTkBE+ONF\nA4/rGKF4dP76KstKg9RZFJe5fAHi8w0HeOLjDby2ZCcFJVUHvytzuwG44JlvGf7owurPPW8dU1/N\nDFhWUu7mqn8tpvs988jO11yDUs1BOOsIOgG7/T5nASOq2faE562IPZ6pAo6lXiGYskqBIP9oOac8\n9AlJsRU/57NfWk1av9+ax5ESF9ef1tW3zhtItuYE73jm9a9vtvvel9vDaOzLL2HRVquSe96qbJ1T\n2XawqIyhj3zKc9ecyiS/psVKNQVNoumIiEwVkUwRyczJyWmUNPgCQaXlP9x3NmseOoefDO1U6zEc\n9TS+tP8EN4/OW+cb6bQgSB3DlgOFfL0ph1tmL/ctqxxIQjHziy389KWlTbJT2u6DxTz+8Yaw9p/Y\naA8U+PJ322vZUqkTTzgDwR6gs9/ndHtZnRljXjDGZBhjMtLS0uolcXUV5RBuGduD928bHbC8VWIM\nLWKj6Nc+uZo9K9TXPAOHiitGOPV/ag8mt9Da1n+E1GMJBLsPWsVA+/Ir6hTqcxykcLr1tRX888ut\nbNpfGLZzeINMfeX6lGpI4QwEy4DeItJdRGKAK4G5YTxfWIkI90zux6D0lKDrvZ3BOqXE8+QVpwTd\nJi6q9nGLQnHeP74Nedvcwsoti+CrTTlBJ86pSVy09V/FfxKeptIvraTcHfZzeL8LR5PIY6vj4iqF\n3Uth2Uuw8WMor9rgoqkJWx2BMcYlIrcDCwAnMMsYs1ZEHgYyjTFzRWQY8B7QCvg/EXnIGFP3Lrsn\ngPMHdWTeqmzuPb8/GV1bkZ1fwuSTOzD+L18CcO951QeRhvbsl1t9dQhg9WEYPeNzXr1xOIPSWwbd\nxzu8dlFZRfFTTRmCLQcKmLN8D7+b1KfR52D2+J7WG+IcmiOok6Jc+PBXsO0riI6DNidBh1Og83A4\naTJEHeNIuUcPQeYs2PEdRMVB6+7QpjekdIVW3aBlOnhcULjfuqnvWgw5GyA2CVr3gB7jrFeUX4eb\nnYvgm7/C9q/B7TfvSEwS9JkEw34G6cPgSJYVLJI7QUxC1bR5PJC9EjYtgPwsSGhtbZvcEVwlUJIP\nvc+20tlAwtqhzBgzH5hfadn9fu+XYRUZNXkdU+L53+2n+z7fOq5XwPqbx/TwDTIH8KeLB/L791bX\netwOLePIzg/vE8cSu9z/D++vpmvrqp3noKIPxOHiipxEbmEpS7cfJDbKQYeWcbRNrujlfNHMRRSW\nurjljB60CnHYa2MMz3y+hfNP6Uj3IJ34jtXxZlx25RWzNbeQ8X3aVruNNxA0dtCrlccDe5ZbN8rO\nwyG+hocTjweKcuDQdijYB9EJ0GUExAV/WCB3C+z4BuKSIakDtDvZel+dfWvgjSlQdAAGXW49Wexb\nBctehO+fgeR0GDEV0odDUnvrFR1kEMiyIuuGv/Vz2L0EygqtG2x5MbQbaN3wty60brLViUmCdv3h\nyB4rKC1+1lp20kQrMG1aADu/g8S2MHwqdBkFHQZBziZY/z9YNxdWvw2OaPDYfyOOaOgxFjqPBGc0\nFB6wgsTORdb3Kg5o0Q6KD4K7as6dDqdAx6HW952fBQe3wul3Qf8Lqr+OY6Q9i8NsSJcUzu7fDoAo\nv2EdLhjcMaRAMH/aGIrL3by+ZGfIg9vVlbeeYffBo9U+5XtzBP5FSi99u52Xvq2oo9gx4zzfe2/n\nuGBNXatzsKiMv366iTeX7ea76WeGtE9+cTm/f281j158MikJ1QQc+5oe/3gjL16XEXJ6vMb/9Uvc\nHhNwfVVO4S0aqi0OHD0M+9dA3hbrRtlxCDjqp8iwRqUFsPINWPq8dW4AZwwMvQ5G/sJ6Chaxbv45\n62HFbFgzx7ph+YtNhjG/hhE/t57gAQ7vgi9nwMrXArcVJ5x0Dpx6PfSaEHid6z+Ed6dageKG+dDp\n1Ip1bpd1U//2Sfj0/sBjxiZDYhuIb209SZcVWzd/T7n15N95OLTqCt3HWudtf7K1n8dt3eQP7YBD\nO+HIXiu3EZdinbvdgIr0ucqsp/71c2HDPFjzDrTsAuc8Zh3T/yk/pQv0ngCTZsAPr0H+buu7jE6A\n/aut/bd8Zm0bnWDd+HuMg6bujvIAACAASURBVF5nW99JYqr1n6c4z7rZO6PBGWude+vnsO5967dL\n7mQdN6riYas+aSAIs/duHR10eWJMxR/F+7eN5qKZwWcua5UYQytqLoY5Xuv9OrJlHaraN6Db9Hn8\nasJJALUOfFfZ0XI3O/OKKHN56N0uKaR9/IufvPbll/C3TzfyyEUnE+tX1/Lyou3MW51Nz7YtuOvs\nk4Iez/vVfbZ+f53S7hXKnBDVFg0VH4QVr0LWMutp9/CuwPXxrWDg5TDq1pqLAoyBvT9YT53ZP1o3\nhJgEiE60npRb97CKFjoMhhZ+DSoOboel/4IfZkPpEeumd/HzVtHIqrdg+cuw7F/WU2dSRzi803qS\ndkRDn8nQbYx1s2uZbt2sFj8Lnz1g/TvgJ9YT7ob51tPtadOsG6W7zLqpbf8afnwDNs63nu4HXGQV\nmezJtK6l41C48nVI7hB4rc4o60n8pIlweDfkbITCfVYxTsF+KM61vtfC/dZ5R/4Cep5pPaVHV3Oj\ndDit60jpAt1r+TGjYqybe+8JcP7fre8tNrnmCqCYRCv3EuAKmPhHK1gZt1XsFIyIFdwS21QsG3OX\n9WogGggaiYjw8g3D6NwqgV5tW/CrCSfxZDXzCEDjT1n5/bbcY9rvaJmbc//xDRCYY8grLGXj/gIG\npafQIjYKj8dQXGZV6ga71oc/XMv81fsY16ct5w7sUGV9Y/Om2RcGDm4jb+FTtNr4Xxyuo5DaGzpl\nwKk3QPtBVpn13h9g40dWWfbS562bVHwr6yafmAaOKKs4o7wYcjdDQbb1FN9xCJQctp5qy4qs5R6/\nyv/WPa1ihdIC62nU4YT+F8KIX0DnYRXbdTvderrf+rkVpAr2Qc/x0LafVT7fIkgLvR5jrRv8t3+H\nzJcgIRVG3QYjbrGCBVYRX2mrk4jrfTaceR9s+sgKhov/aRXtdBgMEx60cxW1zPeR0tl6NRaHo+bi\ns1AEqyc4wWggaGALfnkGOQVWeaB/mfOdE3ozZ8VurhzWhT8v2AjAO784zbfev/lnY1i87eAx7Xe0\nmhY7Fz+7iF0HiwHY/ti53PHmD8yzh9PwjqXk9hjueXcV147qxvzV1sxv1Q6hXUOWqb76D3g8pqIv\nyOFdsP0b6yYNdNqbz63OjZx5IBue3An5u0gyTua4T+fyaU9A275VD5jaEwZeCkcesZ6c96+zyrfL\niiBvq/UUGR1vl82PhN4Traf0+FaBx3G7oGCv9RS+ewnsXkrZ7kyinVHImF/DsJus3EIwrbpCxg11\n+yK6n2G9jKnSw9LjMfT4vVUtmHnvBGvo9f4XWi93uVVcpE2rTjgaCBpYn/ZJ9GkfPIv4zd1Wubg3\nEJzateIP3u03C9r95/fn2S+3kltYyo2juzPrBOrEVFLuZvb3O32ft+YEb7vvDQIA23OLfEEAKppi\nbs8t5K3MrIC5n121DJgXTNAwULDPqrQryMaVv4eDuTlk7srnzJ4tiDN2i48uI6HTqfSWLDpIHu4V\nuTiyV1j75Qbm3gYAA6LhQFlH6D4CRtzCmLkt2U9rLreDwKPz1vHeD3vIvPfswLQkd7SezP28tmQn\ngzqlMLCaVlwBnFG+Yg/TZRTfbcnjmpeWcNWILvzprLoNg1InQSrGy/3+n+7LL/HNwWGlM/i83Krx\naSBoIvxHIe3QMo6uqQnkFpYyeWB7XyBYef/ZjJ7xOUVl4W83H0y36fOqLLt7TsVIq3e9tZKz+7Vj\ncqWinQMFgS0mamqBU5dJdV78ZhudWyf4MgtRuKxKyh9mw+ZPrSduAEcsHncCw3BTtj2JuKQk2Pal\nVVwDfOq9l30IxCZT2C6D7EEX0vv0SzEJrVm95wjbc4v4/QebGTOgO89ddioej2H/3IAGc7V2/vMq\nd3v4w3trEIHtjwVWUBtjmL96Hy6PhzG902htt8janlvEnOW7aZ8cx33/WwvA60t28eGPe1n14Dkh\nf2c5BaW0TowJOt/G7oPFiEB6q+qLOvz7mQTLiJWUu7lo5nc8eMEARvZIDTld9e1/K/fw5cYcnrxi\n8HEf6553V5N1qJjZNwWOoPPN5hx++tJS5k07nQEdQwjojUgDQRPhX24eF+30/aGWuz2M75PGFxtz\nSEmI4dO7xjJuxgLOcSzjsuR1pBevQzB87xnAPM8Ilnn6UkY0V4/owmtLdlV3uqAceOgnO+kiB9hq\nOrLZdMLUoU/iuyv28O6KPVVa39zxxg8Bn72BIFgP6Nnf7+Sc/u1pmWA9XSaXZPFQ1MtctHwNrHHY\nRSnx0OlUvv2+LQUmngzZz6+jVzHW8SP8twhatIfR06D/RdCqKw99nMVs+7u4d0I/a/wkt4s/v/Im\nB7etoMAkkG1ac+nYoUyZOIaTf/8xANsv7sNHa/Zx62sbGdolhSLicTisMZh25FWM47R856GA3F1t\nvBX2wW6k76/cw6/++yMAN4zuxgP/Z3W7uf7lpezMK2Zkj9YB2x8p8e/3YRj04Cf85pw+XHdaN8Ab\ndFZz2/heJMdFM+zRz5h6Rg9+f26/Kuce88QXgFXXM/v7HZxxUhpdUwOb+QYEgiB5sa05hWzYV8CD\nc9fy8S/PqOWbCGTq0ETXGMPC9QcY1yctoLWe151vrgSol0DwxtLgf0efrrMaJyzfeUgDgaof/n9g\ncdFOop3iWz7r+mHWTePwbjouf5mlCS+R4jlMOamU9x7Ot5sOcIFzEVdFWUNL7zcptMs7iavSW/PV\nvhgKTRweHBQTy17Thr0mlRhcdJEDdJH9dHPsp6fspafsJVkqinQOm0QWeobwoXsU33oGUh7if6dN\n+61xeVpSSLrkkFaUT3vnQTrIQdpzkLZyiI1PziQ93sX/Yg7gwEMrKSSBEvJyWrL6sRRS2qZzcvJR\nrtv2DW6ng52JZ9CySydwHYWSI7DqbV6JqbgZ55pkPvOcyoAJP6XFgEl0blPRvj0hbp/vve8m44zi\nB08vFrkrbuDLvyxiyqSKFksT/vaVb+C+FbsOW/sj3Pb6ioDrveSfiwKCn9tjapzhbv8Rq727/yCC\nYBW1rLTPA3DAbz6KQvuGHyx4eM9X7jYUlLp4YO5aXyD4YddhX/HbF78ZB1gTJwULBL5zlbq4739r\n6ZqawFe/HR+wzr9oyD8tG/YdYfHWPDK6WYFqz6GjbNxXQPuWcew5dJTvtuTyszOqH8CwoKScgQ9+\nwr3n9QtpoMPPNxzg5lczuf60btx0enc6t274Clvv9Z/gPUsADQQnJAce6+n1g0+tJnseF9fuOcKI\naAfZpjXdVy3iuVaFrGp/kJGbv0I2uZA9mbDP6pewOWY4TxeM5efX3Mxpvdoydfo8YiljnONH+shu\nOkkuV0R76Ju/hj5R2URRc1HSPtOKrZ6OfOgZyWJPf7aZ9vSRLEY513G2I5NLnN9SYOJZ6unLBtOZ\nFZ7eLPb0p4jAFiExlDPSsY4V/3yF72KX00kCB7DzGOEAKRwwKbgPHWZ7QQIHTRIeHGwynSk2saTK\nEdrLQVJyl0N0R/7pvoBXXRO5su8w7prYp+JgZcVc8cCzxEg5B0wKm0y6lXv5CPjom4Abs3+Q9d6f\njTFBJ+f5elNFu/pgo7fOW51dZVlleUWltE2Kw+0xlLs9nPXXr2ibHMt7t45m3qpsXyCpPCnRyMcC\nhwz3DybegQiD9dsoKXeTGBtFiSvwdzbGsPlAge+zt4+IMda66p68D9tjXRWVuvlmcw4dWsbTq20L\noPIQJNb7zzfs58ZXrOHM75ls1ZcUlLo45+9fExPl8OX8bh7TvdpzHiyyzvnKoh0hBQJvceMri3bw\nyqIdvt87oMK/BvnF5Vz90mJ+f24/TuvZptbtg/GNxXWMnQxPf9x6cPv2d6H1qTkeGghOFMZY3c7X\nzeXr2FdJl1xYk2xVJDqi6eIopY0jlw5yEPOjIPGtGO1wwuoyqza0wyAYOx0GT+Hvc/byXX4ePzMV\n/wFLieHks66mXXKc9Qd/Rg+c9nmn/Wcxn6zNJomjdJA8Okku5USx07Rjt0mjhKrzWq4xPXjHcwbR\nuDjdsZoJjhVkODZyhmMV0VFuSkw0Sz192WY6EIOL7rKPQY6tJEopxSaWrz2DeNkzid0mjRyTwj7T\nmgOk4PL/L1lW5bQBXp8wgr+8uASAnX6VzwB/+3I3S0y/GrsVZx0qJq+wLKAC2tsPYPbinezIK66y\nj3eU0bryn7th+KML2THjPP40f72vQ94eO+j45yZctbQUCwwE1rbBxlU6agcC74REXs9+udXXMAEq\nRk41GG6ZvZzVe/L5/p6zAKsOwut/K/cCVs/yn760FKhoGuw/Mq7LY8g/Wu4LAgCPfbQhIA3+xX9u\njyHKGfym6S0are078ao8IGK36fO4dlRXXv1+J5/dNTbguMFyZ4Mf+QRj4Oezl1dbx7JxXwHn/P3r\natPgTUGoYeDTdfs5pXNL2iZZfSEqiggNv3tnFZcMTWdEmOpVNBA0Jo/H6mi0fq71OrwLxElix9PY\n0e8qup12qW+slZYAxeWQEF3rfyynI7CpZa+2LdhyoJA7zupddWMRnrhyOHPv+5gSYskxKawyPats\ndlbftizccKDK8nKi+MIzhC88QwCIpYwhji1McizlVMcmfuLYSinR7DWpvO0ey1eeU1jkGUAp1nX1\nSEtkWy3zIlTnKjsIgHVzunF0dxJjo7j99RVsqOWGXVLu5vTHrTLvKcMDZ5r7x8LNLNsRvLns28t3\nB11em8ue+z7g85l//bLW6/YvZgnmvR/2cN/5/bl7zo++ZrrBrvuo3XigcpDwDwJQcYM3Bj5ZF9j5\nzjtmVrD9/PlX5pe7PHUa8K/M7SHK6aDc7eHNpbuYMryLr3zfe33lbk+NuRWvYG0KXrVbs63Kqihe\nK3d7cNo9il32+aGiWCdY8+dyt4cJf/uKlPjQWkGJwL++3kaX1ATOGdCe4jIX8dHOgGsoKnXxs1cz\nOSW9ZcBQNWDl8t7KzGLO8iy2PVZ97/bjETmBoKzYKjrp0shz4xhjjfXy45tWZ6IjWVYnoR7jYezv\noM+5tEpoTbCqRW8FaW1+O7EPWQeLfRWU86eNqXHIaO/wETV58boMrnxhMUu219yfoJQYFnv6M+3G\nG/g/vxt1MBP6taVbaiLbcuqn+etlz31f63zMXtP95o327y393ZbcKjdBf8c6lHXlHtvBgsCfFwQ+\nLXt/splfbOG9H4KP4D7tjR/4dkvNnf28N+NSu2hIpOa+FeWVvsNQ+mHsP1LCiD8t5PfnVvSXOFRc\nzog/VT8DXpXzugzEWDfsRz5ch8fAOQPa0zYp1levlFdURvd7rNZY6x4+h4SYilvYoq25tGkRy0nt\nkmpMs/+IvF9vyqFFbBQ927ZgxJ8WcvWILnzh98BT7jY89tF6tuUU8fSUIUx/ZxXXjOzKzrxidgY7\nuJ/X7QYIgvhmGlz6h7MY/ujCKnUd3qKsHXnFLN1+MKDIzpuTC2ef0sgJBN89BV8/AXdvq9ohpyEU\n5Vljtyx70WqDHhVvdYs/6z6rk1B1A3kdg4HpLfncrviD2udK9vffqSO54oXFTBrQnoHpLX1PfyJC\nj7QWtQYCr9N6BZardkqJ9xV/eJW7TZ2ag944ujursg6TufNQ0PWhBgGA9+2nX4Bdfi18CkrqNoRG\nfQo2llSpy13jE7j/3BTVyc4vIaewlKyDFa2RvDfTYPb7VUJ/vzXPNwR5Td5aZuWU/Fuifbhqb3Wb\nB1Xm9vDxmn3stH+PNXvyeWDuWrq3SQwomvL6dN1+EmKiyNxxkHvO7cdV/7IePK4c1rnajowAf5pf\nEXCn2hM2/e3yU6qk3+v5r7YB8PbyLN5fuZdvt9Q8OdPXm3JwVZOby7PnB/nvst0BgcDbQCD/aDmX\nPx+Ye8wrCjIgXT2LnEDQYxx8NcPqHt//wtq2Pn7eMv/Nn8LmTyArEzDWMAMXPGOloaaRGRtY68QY\nRvdqw4geqcy8aijj+qSRGBvF+D5tfWWo95/fn0tPTSclIZqz/vpVwP6927Zg8wHrablHkJFDv5t+\nJuVuD73/8JFv2RXDOvN5kOImgG6pCVXK6P9wXj+e/nxzlUAwpEsKP/i1pqmrH7Pyfe9PtBnY/GeW\nC2bt3iM1rge4dtbSYz7/lH8tDmm7xdut7y3W76EjWLPNmtz2+gqW+j1o7LNvjsGCAMDWA4X843Nr\nAD3/5tVvLqt78V2whgGV3ff+GiD4HB8Aox5byDd3j6/yfR8+WhGsvRmVzQcKWbMnn0Vbc1m+8xBf\nbqx+5sUzK/2thUPkBIL0DGtY2a1fhCcQuF3WqI17VsDeFbBloTUSIWIN9DVuuvXk3yH4pDWNbcV9\nFb1dzxtU0eGrf8eKYBUf4/QVN53atRXL/W7IiXZTx04p8cy9I7CM0yva6eAnQzvxydr9TOhnjRn0\n7oqKXsPnD+rA2r1W56xxfdryyqIdAfs7HUK75KqDiqWGOMx1Q6n83RyPmm4QJ5Lv7Kdk/9znhuza\ng5S/pZVymzU1sQV8QQDgxW+Pr3hxZ5CGAXWVnV8SdMIn/1n9vONugZX7qK4PQnXKXJ465fBDFTmB\nwBltDbK17Yv6OZ7bZY2iuP0bawz23UutNuxgFfN0GQXjf2+ND5N4bM3PTmQT+rULuNndd34/Lnvu\nex6+cAAt7KAwb9rpVWZT+9vlgR14/J/krjutG89+sYXtuUV0Sgk+GNllp6ZTUFJOamIsR0rKmTK8\nC795+8cq243o3ppDxWW+Mv1JA9rz9eYc38B2dXVKesuAnENNnrpyMH9esJHs/JIqNzeAW87owfNf\nbzumdJzo1uypuPl7c4jVadMixjeVajANOdDiHL8HkuNx6h8/q7Ls1e+D1yZ88ONe2iXHBhTF1eat\nzN1cM7LrMaevOpETCMAaWXHTR9bQvK1rG4u2GsbA2vdg4UPW2OZgjSs/9FprdqJOQyvGdm/Gfj62\nBxcO7sg7y7O4ZmRXWiXGVGnR4O1NefGQTtUe548XD2T29zv57Tl9cDqEolLrRt0hJfhwwlFOB1PP\nCGzVdO95/YmLdpKdf9T3ZPrfW0aRf7ScDdlHWLB2P9Mn96XE5WbQg5/49uvcOt43FzNYPXVf/m5H\nlXOOPSmNhy4YwDi/ljO+9DiEW8f34h8LNwMwsFNL0lsl8NSVQ3jog7VBA8E95/bjhW+21cvQ4pXr\nXhzSdKYQ9bZmmti/XdAK+m82H9uIt8eiMabfLix11XlY99N6hqf5aGQNA9hrgvXvxuorympUlGvN\nqDTnBohpAZe8BL/dBr/4Ds59AgZdZo0o2cyDAFiVxx1T4rnjrN41zkC25dHJvoq4YDqlxDN9cl9f\nMUCB/YeR5jdY2eZHJ7P6wYnVHqN9yzj+ctkpzLp+WMDylvHRjOiRyv3/15+YKEfAnNFjerdh4V3j\nArYfbvd6nXZmxexyn/7qDP5943C6VTNj2vf3nMVdZ5/EmX3bMrpXKh/4FYtd5dcs9fmfnhqw34Jf\nnsHPx/bkzL7Vz3oWTOUhJCpX5PZtH1jv9NVvxzHn56PqdA6v2TcNP6b9KouvplWat0LX2xktFF3C\n2EO4ulzoieKWM3rQIy3076ouIisQpPa0xoJf+17d9z24HV462ypamvgo3PK1NYRwYuMNnNUURDkd\ndZq+sXMr64+xQ8uKP8pop4OkuNqbzvpPWBOMd1iOuGgHs28aQUyUg9G9Kn6/SSe3Z/3Dk/iV3wQ3\n/pPpJMVGEeN0MKpHKved35/tj51LWpIVsGZdP4zXbh4ZcL7e7ZLYMeM8dsw4j3MGtAegrb39Se2S\nmD65b5WmmrXx5pjAusH+blJfFviN2VM5MHRKifcN6wBWAGqfHEdyXBQ/H1u1v4j//sO7t2bSgPb0\nqWVCocpBrrIBHYM3ivDmXFJbVO2wWJ0vfzOOZ64aQv8O9d/QYkSP1r5B/KqTHBd6Icr/bgs+KVVt\n7vB7EPE3wZ7pMBwiKxAADLjY6sRVeaaomuTvgX9fYM3zet0HcNrtDTO9YAT682Wn8PL1w+iSmsAt\nZ/TgvVtPq30nP73atuC28VVvcGDlYh6/ZCAf3jHGt+zFa4cFrI+PqejoM7xb4NP3snsnsOrBibwx\ndSQ3nV79cAjV+ejOMXw4LbAi/c6zetO/QzKT7EDh1Sklnsszqk7n7R3CfHyfNNY/MomJA9rTKrEi\nSHorEm8f34sdM87ztdzx1rumJcWy+PdnserBc7h5TEXxaEbXVvz2nD7ccabV6XDhr8cSG+XkuZ+e\nysmdqjZt/vRXZ3Bm37ZMGd7Zd1OOj3b6gsI/pgzxbXvJqdZ13DquJ78OMotcUpCbq/+1f3Rnxe/l\ncAjnD+pYbfPMYMb1sSbY+fOlg5g37XTuntQn6HapiTHcWanT5b3n9QvI0b5n39wHdEz2BXn/xhX+\nEmP9xqXqF5jz++D24A0qAEZV6j381W/H8fbPRzGs0v/H+hRZdQRgTZe38CFY8y6c/svaty8+CP/5\niRUErv8QOh7/aIWqei3joxlvF5fcU8PAZ9XxHz4gmCuGBfYijo9xcssZPao8Ca6472wSYgKDfSgd\n72rSL8hTbEa31sy/cwzGGLrfM5/EGCdrH54EQHGZi0Vb88g6dJRrRnZhSOdWnDuwA3+86GSi/FrU\npMRXpD3a6Qg6t/KQLlZLJv/esNF2kIhxOphjT4JkjOFnY3oEtEzxzyWM7pXK1SO60rtdkq8oLs9u\nTtmrbQvOGdCe7Y+di4gwzR5VdsrwLlw5rLMvcP71U2suh79cdgrr9h5hfJ+2JMQ4KSl3+3IJ087q\nzZ8uHsiug8UBuUOvx34ykMc/2shL12f4Gic89tEGXvCrhL97Uh/6dUhmWLfWrM8+4ruRxkc7eeLj\nqn0zkuOiOWdAe/40f71vzKZxfdLo1TaJu96yGiS0Sohh/rQxdPSrwzrq1wDhvIEdOKldEk9+tonU\nxFi78x70TGvBZ+sP8MsJvSkscQWdk+Tm07vzk6Hp9O+YzPu3jeaV77bz6MUDSYyNqjLKa32T+pq9\nqaFkZGSYzMzM2jesyaxJ1nynty+vebak0kJ49QLYtwaueQe6j6l+W6WO07srshjSpRXdq6mPqInL\n7eGBuWu5dXyvoGXd+cXl7D5UHPB0X1Lupu99H3PeoA7MvGpotcfOLSxl1GMLKXcblv7hLN9YOP7e\nWrabcX3SaOvXvPffi3bQNTWBcX0Cn4Y37S8g2ukIep07cov4bP3+gByX22Poac96FizIeb33Q5Zv\niO73bxvN4M7VTzGZV1jKYx9tYM7yitZC087s5Ru40BhDXlGZb2Id71wb3iDnb8oLi/l+Wx592ycx\n+6YRpCbGUFjmIjkumt0Hiykuc9M1NYG3MndzxbDOviLM619eypcbc4hxOvh2+vig32t9EpHlxpiM\noOsiMhCsehvevdm6uXsrkCtzlcLrl1vNQ6+YDX3DM8aHUo1pR24RHVLiaq1faWwPfbCWySd3YHj3\n6otHjDEs3naQkT1ah1Rsd8vsTF+Lsswdh5hxycDAGdX8eANBsEC05UABT3y8kX9MGVKnXOPWnELO\n+utXdG+T6BsCPJw0EFTmKoV/DIGkDnDzZ1Vb+bhdMOd6WP8BXPRPGHzV8Z1PKXXCWb7zEDf9exlf\n/HpcjS3fwLppHy1zB60vOVZHSsoZ9OAnTDurN3cFqTupbxoIglnxKsy9Ay58FoZcXbHcXQ7v3wqr\n34JJM2DkL47/XEopFURRqTUSaShzJByvmgJB5LUa8hp8NXQ9Heb92hoPCKyWRP/5iRUEzrpfg4BS\nKqwSY6MaJAjUJqythkRkEvAU4AReNMbMqLQ+FngVOBXIA64wxuwIZ5p8HE64dJZ143/tUkjqCIX7\nwBGtxUFKqYgStkAgIk5gJnA2kAUsE5G5xph1fpvdBBwyxvQSkSuBx4ErwpWmKpLawU2fwvKXIftH\naNUdhv4UWlZtv62UUs1VOHMEw4EtxphtACLyJnAh4B8ILgQetN/PAZ4RETENWXERkwCjbmuw0yml\n1IkmnHUEnQD/gcGz7GVBtzHGuIB8oMqYDSIyVUQyRSQzJ6dpDMurlFJNRZOoLDbGvGCMyTDGZKSl\npTV2cpRSqlkJZyDYA3T2+5xuLwu6jYhEYc3RfmJNEaWUUs1cOAPBMqC3iHQXkRjgSmBupW3mAtfZ\n7y8FPm/Q+gGllFLhqyw2xrhE5HZgAVbz0VnGmLUi8jCQaYyZC7wEzBaRLcBBrGChlFKqAYW1H4Ex\nZj4wv9Ky+/3elwCXhTMNSimlatYkKouVUkqFjwYCpZSKcE1u0DkRyQF2HuPubYCGmxH7xKDXHBn0\nmiPD8VxzV2NM0Pb3TS4QHA8Ryaxu9L3mSq85Mug1R4ZwXbMWDSmlVITTQKCUUhEu0gLBC42dgEag\n1xwZ9JojQ1iuOaLqCJRSSlUVaTkCpZRSlWggUEqpCBcxgUBEJonIRhHZIiLTGzs99UVEOovIFyKy\nTkTWisid9vLWIvKpiGy2/21lLxcR+Yf9PawSkaGNewXHRkScIvKDiHxof+4uIkvs6/qvPdAhIhJr\nf95ir+/WmOk+ViKSIiJzRGSDiKwXkVER8Bv/yv4/vUZE3hCRuOb4O4vILBE5ICJr/JbV+bcVkevs\n7TeLyHXBzlWdiAgEftNmTgb6A1NEpH/jpqreuIBfG2P6AyOB2+xrmw4sNMb0Bhban8H6Dnrbr6nA\nPxs+yfXiTmC93+fHgSeNMb2AQ1jToILfdKjAk/Z2TdFTwMfGmL7AKVjX3mx/YxHpBEwDMowxJ2MN\nXOmdzra5/c6vAJMqLavTbysirYEHgBFYs0M+4A0eITHGNPsXMApY4Pf5HuCexk5XmK71f1jzRG8E\nOtjLOgAb7ffPA1P8tvdt11ReWHNbLATOBD4EBKu3ZVTl3xtr9NtR9vsoeztp7Guo4/W2BLZXTncz\n/429sxe2tn+3D4FzmuvvDHQD1hzrbwtMAZ73Wx6wXW2viMgRENq0mU2enR0eAiwB2hljsu1V+4B2\n9vvm8F38Hbgb8NifwaSYagAAA5xJREFUU4HDxpruFAKvKaTpUE9w3YEc4GW7OOxFEUmkGf/Gxpg9\nwF+AXUA21u+2nOb9O/ur6297XL95pASCZk9EWgDvAL80xhzxX2esR4Rm0U5YRM4HDhhjljd2WhpQ\nFDAU+KcxZghQREVRAdC8fmMAu1jjQqwg2BFIpGrxSURoiN82UgJBKNNmNlkiEo0VBF4zxrxrL94v\nIh3s9R2AA/bypv5djAYuEJEdwJtYxUNPASn2dKcQeE3NYTrULCDLGLPE/jwHKzA0198YYAKw3RiT\nY4wpB97F+u2b8+/sr66/7XH95pESCEKZNrNJEhHBmultvTHmb36r/KcBvQ6r7sC7/Fq79cFIIN8v\nC3rCM8bcY4xJN8Z0w/odPzfGXA18gTXdKVS93iY9HaoxZh+wW0T62IvOAtbRTH9j2y5gpIgk2P/H\nvdfcbH/nSur62y4AJopIKzs3NdFeFprGriRpwMqYc4FNwFbgD42dnnq8rtOxso2rgJX261ys8tGF\nwGbgM6C1vb1gtaDaCqzGapXR6NdxjNc+DvjQft8DWApsAd4GYu3lcfbnLfb6Ho2d7mO81sFApv07\nvw+0au6/MfAQsAFYA8wGYpvj7wy8gVUPUo6V+7vpWH5b4Eb7+rcAN9QlDTrEhFJKRbhIKRpSSilV\nDQ0ESikV4TQQKKVUhNNAoJRSEU4DgVJKRTgNBEpVIiJuEVnp96q30WpFpJv/KJNKnQiiat9EqYhz\n1BgzuLEToVRD0RyBUiESkR0i8oSIrBaRpSLSy17eTUQ+t8eHXygiXezl7UTkPRH50X6dZh/KKSL/\nssfa/0RE4hvtopRCA4FSwcRXKhq6wm9dvjFmIPAM1iioAE8D/zbGDAJeA/5hL/8H8JUx5hSssYHW\n2st7AzONMQOAw8AlYb4epWqkPYuVqkRECo0xLYIs3wGcaYzZZg/0t88YkyoiuVhjx5fby7ONMW1E\nJAdIN8aU+h2jG/CpsSYcQUR+B0QbY/4Y/itTKjjNEShVN6aa93VR6vfejdbVqUamgUCpurnC79/v\n7feLsEZCBbga+MZ+vxD4BfjmWG7ZUIlUqi70SUSpquJFZKXf54+NMd4mpK1EZBXWU/0Ue9kdWLOH\n/RZrJrEb7OV3Ai+IyE1YT/6/wBplUqkTitYRKBUiu44gwxiT29hpUao+adGQUkpFOM0RKKVUhNMc\ngVJKRTgNBEopFeE0ECilVITTQKCUUhFOA4FSSkW4/wejJrRsrx3pQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP10GvQ1QfHY",
        "colab_type": "text"
      },
      "source": [
        "## 保存模型 & 模型可视化 & 加载模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbk7iG4DQfHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import load_model\n",
        "# 保存模型\n",
        "model.save('model_MLP.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "#模型可视化 pip install pydot\n",
        "plot_model(model, to_file='model_MLP.png', show_shapes=True)\n",
        "\n",
        "# 加载模型\n",
        "model = load_model('model_MLP.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lADXbGNGQfHj",
        "colab_type": "text"
      },
      "source": [
        "## 模型的预测功能"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2ugNwWyQfHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "755a69fd-b942-4107-cab4-8653623e4aa9"
      },
      "source": [
        "# 预测\n",
        "y_new = model.predict(x_valid)\n",
        "# 反归一化\n",
        "min_max_scaler.fit(y_valid_pd)\n",
        "y_new = min_max_scaler.inverse_transform(y_new)\n",
        "print(y_new)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[500.0429 ]\n",
            " [500.02518]\n",
            " [500.0429 ]\n",
            " [500.02518]\n",
            " [500.6449 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42o-aGnpiOrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}